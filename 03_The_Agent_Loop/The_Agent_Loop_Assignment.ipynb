{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Agent Loop: Building Production Agents with LangChain 1.0\n",
    "\n",
    "> **Note:** While this notebook can be adapted to use various LLM providers, we'll be using the Anthropic Claude API. Please follow the best practices outlined in the [SRHG AI Usage Guidelines](https://srhg.enterprise.slack.com/docs/T0HANKTEC/F0AB86J3A1L).\n",
    "\n",
    "In this notebook, we'll explore the foundational concepts of AI agents and learn how to build production-grade agents using LangChain's new `create_agent` abstraction with middleware support. We'll build a **Stone Ridge Investment Assistant** that can answer questions about Stone Ridge's investment philosophy, market insights, and strategic outlook.\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand what an \"agent\" is and how the agent loop works\n",
    "- Learn the core constructs of LangChain (Runnables, LCEL)\n",
    "- Master the `create_agent` function and middleware system\n",
    "- Build an agentic RAG application using Qdrant for Stone Ridge investor letters\n",
    "\n",
    "## Table of Contents:\n",
    "\n",
    "- **Part 1:** Introduction to LangChain, LangSmith, and `create_agent`\n",
    "  - Task 1: Dependencies\n",
    "  - Task 2: Environment Variables\n",
    "  - Task 3: LangChain Core Concepts (Runnables & LCEL)\n",
    "  - Task 4: Understanding the Agent Loop\n",
    "  - Task 5: Building Your First Agent with `create_agent()`\n",
    "  - Question #1 & Question #2\n",
    "  - Activity #1: Create a Custom Tool\n",
    "\n",
    "- **Part 2:** Middleware - Agentic RAG with Qdrant\n",
    "  - Task 6: Loading & Chunking Documents\n",
    "  - Task 7: Setting up Qdrant Vector Database\n",
    "  - Task 8: Creating a RAG Tool\n",
    "  - Task 9: Introduction to Middleware\n",
    "  - Task 10: Building Agentic RAG with Middleware\n",
    "  - Question #3 & Question #4\n",
    "  - Activity #2: Enhance the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1\n",
    "## Introduction to LangChain, LangSmith, and `create_agent`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Dependencies\n",
    "\n",
    "First, let's ensure we have all the required packages installed. We'll be using:\n",
    "\n",
    "- **LangChain 1.0+**: The core framework with the new `create_agent` API\n",
    "- **LangChain-Anthropic**: Anthropic Claude model integrations\n",
    "- **LangChain-OpenAI**: OpenAI embeddings (we'll use Claude for chat, OpenAI for embeddings)\n",
    "- **LangSmith**: Observability and tracing\n",
    "- **Qdrant**: Vector database for RAG\n",
    "- **PyMuPDF**: PDF parsing for investor letters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Environment Variables\n",
    "\n",
    "We need to set up our API keys for:\n",
    "1. **Anthropic** - For Claude models (chat/reasoning)\n",
    "2. **OpenAI** - For embeddings (text-embedding-3-small)\n",
    "3. **LangSmith** - For tracing and observability (optional but recommended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: LangChain Core Concepts\n",
    "\n",
    "Before diving into agents, let's understand the fundamental building blocks of LangChain.\n",
    "\n",
    "### What is a Runnable?\n",
    "\n",
    "A **Runnable** is the core abstraction in LangChain - think of it as a standardized component that:\n",
    "- Takes an input\n",
    "- Performs some operation\n",
    "- Returns an output\n",
    "\n",
    "Every component in LangChain (models, prompts, retrievers, parsers) is a Runnable, which means they all share the same interface:\n",
    "\n",
    "```python\n",
    "result = runnable.invoke(input)           # Single input\n",
    "results = runnable.batch([input1, input2]) # Multiple inputs\n",
    "for chunk in runnable.stream(input):       # Streaming\n",
    "    print(chunk)\n",
    "```\n",
    "\n",
    "### What is LCEL (LangChain Expression Language)?\n",
    "\n",
    "**LCEL** allows you to chain Runnables together using the `|` (pipe) operator:\n",
    "\n",
    "```python\n",
    "chain = prompt | model | output_parser\n",
    "result = chain.invoke({\"query\": \"Hello!\"})\n",
    "```\n",
    "\n",
    "This is similar to Unix pipes - the output of one component becomes the input to the next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Understanding the Agent Loop\n",
    "\n",
    "### What is an Agent?\n",
    "\n",
    "An **agent** is a system that uses an LLM to decide what actions to take. Unlike a simple chain that follows a fixed sequence, an agent can:\n",
    "\n",
    "1. **Reason** about what to do next\n",
    "2. **Take actions** by calling tools\n",
    "3. **Observe** the results\n",
    "4. **Iterate** until the task is complete\n",
    "\n",
    "### The Agent Loop\n",
    "\n",
    "The core of every agent is the **agent loop**:\n",
    "\n",
    "```\n",
    "                          AGENT LOOP                         \n",
    "                                                             \n",
    "      +----------+     +----------+     +----------+         \n",
    "      |  Model   | --> |   Tool   | --> |  Model   | --> ... \n",
    "      |   Call   |     |   Call   |     |   Call   |         \n",
    "      +----------+     +----------+     +----------+         \n",
    "           |                                  |              \n",
    "           v                                  v              \n",
    "      \"Use search\"                   \"Here's the answer\"     \n",
    "```\n",
    "\n",
    "1. **Model Call**: The LLM receives the current state and decides whether to:\n",
    "   - Call a tool (continue the loop)\n",
    "   - Return a final answer (exit the loop)\n",
    "\n",
    "2. **Tool Call**: If the model decides to use a tool, the tool is executed and its output is added to the conversation\n",
    "\n",
    "3. **Repeat**: The loop continues until the model decides it has enough information to answer\n",
    "\n",
    "### Why `create_agent`?\n",
    "\n",
    "LangChain 1.0 introduced `create_agent` as the new standard way to build agents. It provides:\n",
    "\n",
    "- **Simplified API**: One function to create production-ready agents\n",
    "- **Middleware Support**: Hook into any point in the agent loop\n",
    "- **Built on LangGraph**: Uses the battle-tested LangGraph runtime under the hood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools created:\n",
      "  - calculate: Evaluate a mathematical expression. Use this for any math ca...\n",
      "  - get_current_time: Get the current date and time. Use this when the user asks a...\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Evaluate a mathematical expression. Use this for any math calculations.\n",
    "    \n",
    "    Args:\n",
    "        expression: A mathematical expression to evaluate (e.g., '2 + 2', '10 * 5')\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Using eval with restricted globals for safety\n",
    "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
    "        return f\"The result of {expression} is {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error evaluating expression: {e}\"\n",
    "\n",
    "@tool\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"Get the current date and time. Use this when the user asks about the current time or date.\"\"\"\n",
    "    from datetime import datetime\n",
    "    return f\"The current date and time is: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "\n",
    "# Create our tool belt\n",
    "tools = [calculate, get_current_time]\n",
    "\n",
    "print(\"Tools created:\")\n",
    "for t in tools:\n",
    "    print(f\"  - {t.name}: {t.description[:60]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent created successfully!\n",
      "Type: <class 'langgraph.graph.state.CompiledStateGraph'>\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "# Create the Claude model for our agent\n",
    "claude_model = ChatAnthropic(model=\"claude-sonnet-4-20250514\", temperature=0)\n",
    "\n",
    "# Create our first agent\n",
    "simple_agent = create_agent(\n",
    "    model=claude_model,\n",
    "    tools=tools,\n",
    "    system_prompt=\"You are a helpful assistant that can perform calculations and tell the time. Always explain your reasoning.\"\n",
    ")\n",
    "\n",
    "print(\"Agent created successfully!\")\n",
    "print(f\"Type: {type(simple_agent)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Response:\n",
      "The answer is 1,200. When you multiply 25 by 48, you get 1,200.\n"
     ]
    }
   ],
   "source": [
    "# Test the agent with a simple calculation\n",
    "response = simple_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is 25 * 48?\"}]}\n",
    ")\n",
    "\n",
    "# Print the final response\n",
    "print(\"Agent Response:\")\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Agent Conversation:\n",
      "==================================================\n",
      "\n",
      "[HUMAN]\n",
      "What time is it, and what is 100 divided by the current hour?\n",
      "\n",
      "[AI]\n",
      "[{'text': \"I'll help you find the current time and then calculate 100 divided by the current hour.\", 'type': 'text'}, {'id': 'toolu_019SAw3Ui4cnqce9QNw5QwLp', 'input': {}, 'name': 'get_current_time', 'type': 'tool_use'}]\n",
      "\n",
      "[TOOL]\n",
      "The current date and time is: 2026-02-10 00:55:14\n",
      "\n",
      "[AI]\n",
      "The current time is 00:55:14 (12:55:14 AM) on February 10, 2026. The current hour is 0 (midnight hour in 24-hour format).\n",
      "\n",
      "However, I cannot divide 100 by 0 as that would result in division by zero, which is undefined mathematically. \n",
      "\n",
      "If you'd like me to use a different interpretation:\n",
      "- If we consider the hour in 12-hour format, it would be 12 (midnight as hour 12)\n",
      "- Or if you meant to wait until a different hour when division would be possible\n",
      "\n",
      "Would you like me to calculate 100 √∑ 12 instead,\n"
     ]
    }
   ],
   "source": [
    "# Let's see the full conversation to understand the agent loop\n",
    "print(\"Full Agent Conversation:\")\n",
    "print(\"=\" * 50)\n",
    "for msg in response[\"messages\"]:\n",
    "    role = msg.type if hasattr(msg, 'type') else 'unknown'\n",
    "    content = msg.content if hasattr(msg, 'content') else str(msg)\n",
    "    print(f\"\\n[{role.upper()}]\")\n",
    "    print(content[:500] if len(str(content)) > 500 else content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming Agent Response:\n",
      "==================================================\n",
      "\n",
      "[Node: model]\n",
      "[{'text': \"I'll calculate 15% of 250 for you.\", 'type': 'text'}, {'id': 'toolu_01HU7sPshywfRWsuoAFFSshE', 'input': {'expression': '0.15 * 250'}, 'name': 'calculate', 'type': 'tool_use'}]\n",
      "\n",
      "[Node: tools]\n",
      "The result of 0.15 * 250 is 37.5\n",
      "\n",
      "[Node: model]\n",
      "15% of 250 is **37.5**.\n",
      "\n",
      "To explain the calculation: 15% means 15/100 = 0.15, so we multiply 250 by 0.15 to get the result.\n"
     ]
    }
   ],
   "source": [
    "# Stream the agent's response\n",
    "print(\"Streaming Agent Response:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for chunk in simple_agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Calculate 15% of 250\"}]},\n",
    "    stream_mode=\"updates\"\n",
    "):\n",
    "    for node, values in chunk.items():\n",
    "        print(f\"\\n[Node: {node}]\")\n",
    "        if \"messages\" in values:\n",
    "            for msg in values[\"messages\"]:\n",
    "                if hasattr(msg, 'content') and msg.content:\n",
    "                    print(msg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ùì Question #2:\n",
    "\n",
    "Looking at the `calculate` and `get_current_time` tools we created, why is the **docstring** so important for each tool? How does the agent use this information when deciding which tool to call?\n",
    "\n",
    "##### ‚úÖ Answer:\n",
    "The docstrings for the tool functions tell the agent what kind of extra capabilities it has available, and what the expected input arguments and output structure of those functional capabilities are. It can deteremine which of its existing tools is most capable of addressing the most recent message in the chain, without having to parse through the actual logic in the tool function itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Create your custom tool\n",
    "@tool\n",
    "def get_current_timezone() -> str:\n",
    "    \"\"\"Get the current timezone information. Use this when the user asks about the timezone, time zone, or what timezone they are in.\n",
    "    \n",
    "    Returns:\n",
    "        str: The current timezone name and UTC offset\n",
    "    \"\"\"\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "    \n",
    "    # Get timezone name\n",
    "    tz_name = time.tzname[time.daylight]\n",
    "    \n",
    "    # Get UTC offset\n",
    "    offset_seconds = -time.timezone if not time.daylight else -time.altzone\n",
    "    offset_hours = offset_seconds // 3600\n",
    "    offset_minutes = (abs(offset_seconds) % 3600) // 60\n",
    "    \n",
    "    # Format offset\n",
    "    offset_str = f\"UTC{'+' if offset_hours >= 0 else ''}{offset_hours:02d}:{offset_minutes:02d}\"\n",
    "    \n",
    "    return f\"Current timezone: {tz_name} ({offset_str})\"\n",
    "\n",
    "@tool\n",
    "def get_time_hours_ago(hours: float) -> str:\n",
    "    \"\"\"Calculate what the date and time was a specified number of hours ago. Use this when the user asks about past times.\n",
    "    \n",
    "    Args:\n",
    "        hours: The number of hours to go back in time (e.g., 2.5 for 2.5 hours ago)\n",
    "    \n",
    "    Returns:\n",
    "        str: The date and time that many hours ago\n",
    "    \"\"\"\n",
    "    from datetime import datetime, timedelta\n",
    "    \n",
    "    try:\n",
    "        past_time = datetime.now() - timedelta(hours=float(hours))\n",
    "        return f\"{hours} hour(s) ago, it was: {past_time.strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error calculating past time: {e}\"\n",
    "\n",
    "# Add your tools to the tools list\n",
    "tools = [calculate, get_current_time, get_current_timezone, get_time_hours_ago]\n",
    "\n",
    "# Create a new agent with the updated tools\n",
    "simple_agent = create_agent(\n",
    "    model=claude_model,\n",
    "    tools=tools,\n",
    "    system_prompt=\"You are a helpful assistant that can perform time-based calculations, tell the time, provide timezone information, and calculate past times. Always explain your reasoning.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2\n",
    "## Middleware - Agentic RAG with Qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Loading & Chunking Documents\n",
    "\n",
    "We'll use the Stone Ridge 2025 Investor Letter - the same document from Module 2 - to build our investment assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 133 chunks\n",
      "\n",
      "Sample chunk:\n",
      "--------------------------------------------------\n",
      "2025 Investor Letter\n",
      "Investor Letter\n",
      "‚ÄúEvery driver has a limit.  Mine is a little bit further than others.‚Äù\n",
      "‚Äî‚ÄÇ Ayrton Senna, greatest Formula One driver of all time\n",
      "‚ÄúI‚Äôm not funny.  What I am is brave.‚Äù\n",
      "‚Äî‚ÄÇ Lucille Ball, greatest female comedian of all time\n",
      "‚ÄúI‚Äôd rather be optimistic and wrong than pe...\n"
     ]
    }
   ],
   "source": [
    "# Split the documents into chunks\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_texts(documents)\n",
    "\n",
    "print(f\"Split into {len(chunks)} chunks\")\n",
    "print(f\"\\nSample chunk:\")\n",
    "print(\"-\" * 50)\n",
    "print(chunks[0][:300] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 1536\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "# Initialize the embedding model\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Get embedding dimension\n",
    "sample_embedding = embedding_model.embed_query(\"test\")\n",
    "embedding_dim = len(sample_embedding)\n",
    "print(f\"Embedding dimension: {embedding_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 133 documents to vector store\n"
     ]
    }
   ],
   "source": [
    "# Create the vector store and add documents\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Convert chunks to LangChain Document objects\n",
    "langchain_docs = [Document(page_content=chunk) for chunk in chunks]\n",
    "\n",
    "# Create vector store\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=qdrant_client,\n",
    "    collection_name=collection_name,\n",
    "    embedding=embedding_model\n",
    ")\n",
    "\n",
    "# Add documents to the vector store\n",
    "vector_store.add_documents(langchain_docs)\n",
    "\n",
    "print(f\"Added {len(langchain_docs)} documents to vector store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: Creating a RAG Tool\n",
    "\n",
    "Now we'll wrap our retriever as a tool that the agent can use. This is the key to **Agentic RAG** - the agent decides when to retrieve information about Stone Ridge's investment philosophy and strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9: Introduction to Middleware\n",
    "\n",
    "**Middleware** in LangChain 1.0 allows you to hook into the agent loop at various points:\n",
    "\n",
    "```\n",
    "                       MIDDLEWARE HOOKS                 \n",
    "                                                        \n",
    "   +--------------+                    +--------------+ \n",
    "   | before_model | --> MODEL CALL --> | after_model  | \n",
    "   +--------------+                    +--------------+ \n",
    "                                                        \n",
    "   +-------------------+                                \n",
    "   | wrap_model_call   |  (intercept and modify calls)  \n",
    "   +-------------------+                                \n",
    "```\n",
    "\n",
    "Common use cases:\n",
    "- **Logging**: Track what the agent is doing\n",
    "- **Guardrails**: Filter or modify inputs/outputs\n",
    "- **Rate limiting**: Control API usage\n",
    "- **Human-in-the-loop**: Pause for human approval\n",
    "\n",
    "LangChain provides middleware through **decorator functions** that hook into specific points in the agent loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call limit middleware created!\n",
      "  - Thread limit: 10\n",
      "  - Run limit: 5\n"
     ]
    }
   ],
   "source": [
    "# You can also use the built-in ModelCallLimitMiddleware to prevent runaway agents\n",
    "from langchain.agents.middleware import ModelCallLimitMiddleware\n",
    "\n",
    "# This middleware will stop the agent after 10 model calls per thread\n",
    "call_limiter = ModelCallLimitMiddleware(\n",
    "    thread_limit=10,  # Max calls per conversation thread\n",
    "    run_limit=5,      # Max calls per single run\n",
    "    exit_behavior=\"end\"  # What to do when limit is reached\n",
    ")\n",
    "\n",
    "print(\"Call limit middleware created!\")\n",
    "print(f\"  - Thread limit: {call_limiter.thread_limit}\")\n",
    "print(f\"  - Run limit: {call_limiter.run_limit}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investment Agent created with middleware!\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "# Reset the call counter\n",
    "model_call_count = 0\n",
    "\n",
    "# Define our tools - include the RAG tool and the calculator from earlier\n",
    "rag_tools = [\n",
    "    search_investment_knowledge,\n",
    "    calculate,\n",
    "    get_current_time\n",
    "]\n",
    "\n",
    "# Create the Claude model for our RAG agent\n",
    "claude_rag_model = ChatAnthropic(model=\"claude-sonnet-4-20250514\", temperature=0)\n",
    "\n",
    "# Create the agentic RAG system with middleware\n",
    "investment_agent = create_agent(\n",
    "    model=claude_rag_model,\n",
    "    tools=rag_tools,\n",
    "    system_prompt=\"\"\"You are a helpful Stone Ridge investment assistant with access to a comprehensive knowledge base of investor letters and company information.\n",
    "\n",
    "Your role is to:\n",
    "1. Answer questions about Stone Ridge's investment philosophy, market insights, and strategic outlook\n",
    "2. Always search the knowledge base when the user asks investment-related questions\n",
    "3. Provide accurate, helpful information based on the retrieved context\n",
    "4. Be professional and informative in your responses\n",
    "5. If you cannot find relevant information, say so honestly\n",
    "6. Include a reminder that information is for educational purposes only and not investment advice when appropriate\n",
    "\n",
    "Remember: Always cite information from the knowledge base when applicable.\"\"\",\n",
    "    middleware=[\n",
    "        log_before_model,\n",
    "        log_after_model,\n",
    "        call_limiter\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Investment Agent created with middleware!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with complex query\n",
      "==================================================\n",
      "[LOG] Model call #7 - Messages in state: 1\n",
      "[LOG] After model - Tool calls requested: [{'name': 'search_investment_knowledge', 'args': {'query': 'energy investments oil gas energy sector strategy'}, 'id': 'toolu_01N41xSgabPAbxnbTvuhjFi3', 'type': 'tool_call'}, {'name': 'calculate', 'args': {'expression': '100000000 * (1 + 0.5)'}, 'id': 'toolu_019aEvRw8fjqnRP1etijsBG7', 'type': 'tool_call'}]\n",
      "[LOG] Model call #8 - Messages in state: 4\n",
      "[LOG] After model - Tool calls requested: [{'name': 'search_investment_knowledge', 'args': {'query': 'Stone Ridge Energy SRE investment philosophy approach natural gas oil'}, 'id': 'toolu_0116y2oaH9GUM3n35yXQ5YxP', 'type': 'tool_call'}]\n",
      "[LOG] Model call #9 - Messages in state: 6\n",
      "[LOG] After model - Tool calls requested: []\n",
      "\n",
      "==================================================\n",
      "FINAL RESPONSE:\n",
      "==================================================\n",
      "Based on the Stone Ridge investment knowledge base, here's what Stone Ridge says about their energy investments:\n",
      "\n",
      "## Stone Ridge Energy (SRE) Investment Approach\n",
      "\n",
      "**Key Investment Philosophy:**\n",
      "- Stone Ridge Energy has purchased almost **$11 billion of energy assets** since inception\n",
      "- All acquisitions are done via **proprietary securitizations** with \"no bankers, no information leakage, no fee leakage\"\n",
      "- They focus on aligning physics and finance, with teams \"crisply aligned on maximizing a singular metric ‚Äì total dollars of operating profit\"\n",
      "\n",
      "**Performance Results:**\n",
      "- Across thirteen equity tranches, their integrated approach has produced **>20% annual returns with low volatility and no correlation to anything**\n",
      "- This performance was achieved despite natural gas prices fluctuating dramatically from $1.50/MMBtu to almost $9/MMBtu\n",
      "\n",
      "**Strategic Vision:**\n",
      "- Stone Ridge sees SRE becoming \"a different kind of company\" over the next five years\n",
      "- Their goal is to become a **top three U.S. producer of hydrocarbons** through disciplined acquisitions, careful development, and process improvement\n",
      "- They emphasize the civic importance of their work, aiming to meaningfully impact U.S. families, factories, and national competitiveness\n",
      "- More than 99% of their managed capital comes from American investors\n",
      "\n",
      "## Investment Calculation\n",
      "\n",
      "For your second question: If Stone Ridge invested $100 million with a 50% return over 12 years, the total value would be **$150 million**.\n",
      "\n",
      "*Please note: This information is for educational purposes only and should not be considered investment advice. Past performance does not guarantee future results.*\n"
     ]
    }
   ],
   "source": [
    "# Test with a more complex query\n",
    "print(\"Testing with complex query\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "response = investment_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What does Stone Ridge say about their energy investments? Also, if they invested $100 million with a 50% return over 12 years, what would be the total value?\"}]}\n",
    ")\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FINAL RESPONSE:\")\n",
    "print(\"=\" * 50)\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Agent\n",
    "\n",
    "The agent created by `create_agent` is built on LangGraph, so we can visualize its structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚ùì Question #3:\n",
    "\n",
    "How does **Agentic RAG** differ from traditional RAG? What are the advantages and potential disadvantages of letting the agent decide when to retrieve information from the Stone Ridge investor letters?\n",
    "\n",
    "##### ‚úÖ Answer:\n",
    "Agentic RAG combines the external information retrieval capabilities of traditional RAG with a dynamic reasoning and action loop enabled by agents. Agentic RAG can generate an answer to a given input question in multiple steps, using tool calls and LLM reasoning each time to hone the current output to the format of the expected answer.<br><br>\n",
    "The agentic approach has the advantage of performing multiple rounds of auomtated reasoning between rounds of external infomration acquisition to get answers to complex, multi-part questions, without requirng a human to stitch the output of one tool to the input of another tool or model reply. The agentic approach can also result in unnecessary use of tools, consuming more tokens and prolonging the time taken to answer simple questions. It also requires the agent to re-check all of its available tools at each step, costing time and compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ùì Question #4:\n",
    "\n",
    "Looking at the middleware examples (`log_before_model`, `log_after_model`, and `ModelCallLimitMiddleware`), describe a real-world scenario where middleware would be essential for a production agent. What specific middleware hooks would you use and why?\n",
    "\n",
    "##### ‚úÖ Answer:\n",
    "Middleware is essential in production agents for monitoring, governance, and reliability across several critical scenarios. In regulated industries like healthcare and finance, compliance and audit trail middleware is required to record PII access, tool usage, and data sources while redacting sensitive information from logs, proving what data was accessed and how decisions were made. For reliability, retry-with-backoff middleware handles transient API failures, circuit breaker middleware prevents cascading failures when upstream services are down, and rate limiting middleware respects API quotas to prevent a single complex query from exhausting rate limits and breaking the service for everyone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üèóÔ∏è Activity #2: Enhance the Agentic RAG System\n",
    "\n",
    "Now it's your turn! Enhance the investment agent by implementing ONE of the following:\n",
    "\n",
    "### Option A: Add a New Tool\n",
    "Create a new tool that the agent can use. Ideas:\n",
    "- A tool that calculates compound annual growth rate (CAGR)\n",
    "- A tool that compares investment returns across different time periods\n",
    "- A tool that formats financial figures with proper notation\n",
    "\n",
    "### Option B: Create Custom Middleware\n",
    "Build middleware that adds new functionality:\n",
    "- Middleware that tracks which tools are used most frequently\n",
    "- Middleware that adds a compliance disclaimer to investment-related responses\n",
    "- Middleware that enforces a response length limit\n",
    "\n",
    "### Option C: Improve the RAG Tool\n",
    "Enhance the retrieval tool:\n",
    "- Add metadata filtering by year or topic\n",
    "- Implement reranking of results for financial relevance\n",
    "- Add source citations with relevance scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Financial Analysis Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import getpass\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import before_model, after_model\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.tools import tool\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "from uuid import uuid4\n",
    "\n",
    "\n",
    "# configure async execution pattern\n",
    "nest_asyncio.apply()  # Required for async operations in Jupyter\n",
    "\n",
    "\n",
    "# Set Anthropic, OpenAI and LangChain API Keys\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = getpass.getpass(\"Anthropic API Key: \")\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key (for embeddings): \")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIE9 - The Agent Loop - {uuid4().hex[0:8]}\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangSmith API Key (press Enter to skip): \") or \"\"\n",
    "\n",
    "if not os.environ[\"LANGCHAIN_API_KEY\"]:\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom tools for the Agent to use\n",
    "@tool\n",
    "def load_returns_csv(filename: str) -> str:\n",
    "    \"\"\"Load a CSV file from the data/returns folder and return its contents as a formatted table.\n",
    "    \n",
    "    Use this tool to load historical investment return data. Available files include:\n",
    "    - vfiax_returns_2011_2025.csv: VFIAX fund returns from 2011-2025\n",
    "    - sp500_returns_1928_2025.csv: S&P 500 returns from 1928-2025\n",
    "    - top_etf_returns_2020_2025.csv: Top performing ETFs from 2020-2025\n",
    "    \n",
    "    Args:\n",
    "        filename: Name of the CSV file in data/returns folder (with or without .csv extension)\n",
    "    \n",
    "    Returns:\n",
    "        A formatted string representation of the DataFrame or error message\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Add .csv extension if not present\n",
    "        if not filename.endswith('.csv'):\n",
    "            filename += '.csv'\n",
    "        \n",
    "        # Construct full path\n",
    "        filepath = os.path.join('data', 'returns', filename)\n",
    "        \n",
    "        # Check if file exists\n",
    "        if not os.path.exists(filepath):\n",
    "            return f\"Error: File '{filename}' not found in data/returns folder. Available files: vfiax_returns_2011_2025.csv, sp500_returns_1928_2025.csv, top_etf_returns_2020_2025.csv\"\n",
    "        \n",
    "        # Load the CSV\n",
    "        df = pd.read_csv(filepath)\n",
    "        \n",
    "        # Return formatted table with summary\n",
    "        return f\"Loaded {filename}:\\n\\nShape: {df.shape[0]} rows x {df.shape[1]} columns\\nColumns: {', '.join(df.columns.tolist())}\\n\\nFirst 10 rows:\\n{df.head(10).to_string(index=False)}\\n\\nData available for further analysis.\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error loading CSV: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def standardize_percent_representations(filename: str, column_names: str) -> str:\n",
    "    \"\"\"Convert string-based percent representations in a pandas DataFrame to standardized float format.\n",
    "    \n",
    "    This tool takes a CSV file and column name(s), converts percentage strings (like '50%', '50.5%', \n",
    "    '0.5', etc.) to decimal floats (0.50, 0.505, 0.005), and saves the updated file.\n",
    "    \n",
    "    Args:\n",
    "        filename: Name of the CSV file in data/returns folder (with or without .csv extension)\n",
    "        column_names: Comma-separated column names to convert (e.g., 'Return' or 'Return,Yield')\n",
    "    \n",
    "    Returns:\n",
    "        Success message with conversion details or error message\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Add .csv extension if not present\n",
    "        if not filename.endswith('.csv'):\n",
    "            filename += '.csv'\n",
    "        \n",
    "        # Construct full path\n",
    "        filepath = os.path.join('data', 'returns', filename)\n",
    "        \n",
    "        # Check if file exists\n",
    "        if not os.path.exists(filepath):\n",
    "            return f\"Error: File '{filename}' not found in data/returns folder.\"\n",
    "        \n",
    "        # Load the CSV\n",
    "        df = pd.read_csv(filepath)\n",
    "        \n",
    "        # Parse column names\n",
    "        columns = [col.strip() for col in column_names.split(',')]\n",
    "        \n",
    "        # Validate columns exist\n",
    "        missing_cols = [col for col in columns if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            return f\"Error: Columns not found in DataFrame: {', '.join(missing_cols)}. Available columns: {', '.join(df.columns.tolist())}\"\n",
    "        \n",
    "        # Track conversions\n",
    "        conversions = {}\n",
    "        \n",
    "        # Convert each specified column\n",
    "        for col in columns:\n",
    "            original_dtype = df[col].dtype\n",
    "            converted_count = 0\n",
    "            \n",
    "            def convert_percent(value):\n",
    "                nonlocal converted_count\n",
    "                \n",
    "                # If already numeric, return as-is\n",
    "                if pd.isna(value):\n",
    "                    return value\n",
    "                \n",
    "                if isinstance(value, (int, float)):\n",
    "                    return float(value)\n",
    "                \n",
    "                # Convert to string and strip whitespace\n",
    "                str_value = str(value).strip()\n",
    "                \n",
    "                # Handle empty strings\n",
    "                if not str_value:\n",
    "                    return None\n",
    "                \n",
    "                try:\n",
    "                    # Remove % symbol if present\n",
    "                    if '%' in str_value:\n",
    "                        converted_count += 1\n",
    "                        # Remove % and convert to decimal (50% -> 0.50)\n",
    "                        return float(str_value.replace('%', '')) / 100.0\n",
    "                    else:\n",
    "                        # Parse as regular float\n",
    "                        return float(str_value)\n",
    "                except ValueError:\n",
    "                    # If conversion fails, return original value\n",
    "                    return value\n",
    "            \n",
    "            # Apply conversion\n",
    "            df[col] = df[col].apply(convert_percent)\n",
    "            \n",
    "            conversions[col] = {\n",
    "                'original_dtype': str(original_dtype),\n",
    "                'new_dtype': str(df[col].dtype),\n",
    "                'converted_values': converted_count\n",
    "            }\n",
    "        \n",
    "        # Save the updated DataFrame\n",
    "        df.to_csv(filepath, index=False)\n",
    "        \n",
    "        # Build result message\n",
    "        result_parts = [f\"Successfully standardized percent representations in {filename}:\"]\n",
    "        for col, stats in conversions.items():\n",
    "            result_parts.append(f\"  - {col}: Converted {stats['converted_values']} values from {stats['original_dtype']} to {stats['new_dtype']}\")\n",
    "        \n",
    "        result_parts.append(f\"\\nUpdated file saved to {filepath}\")\n",
    "        result_parts.append(f\"\\nSample of converted data:\\n{df[columns].head(5).to_string(index=False)}\")\n",
    "        \n",
    "        return '\\n'.join(result_parts)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error standardizing percent values: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def calculate_comparable_returns(filename: str, return_column: str, return_type: str, years: int = None) -> str:\n",
    "    \"\"\"Calculate and normalize investment returns for fair comparison across different data formats.\n",
    "    \n",
    "    Use this tool to convert between cumulative returns and annualized returns, enabling\n",
    "    apples-to-apples comparison of investment performance.\n",
    "    \n",
    "    Args:\n",
    "        filename: Name of the CSV file in data/returns folder (with or without .csv extension)\n",
    "        return_column: Name of the column containing return data (e.g., 'Total Return', '5-Year Return')\n",
    "        return_type: Type of returns in the data - either 'cumulative' (total return over period) \n",
    "                     or 'annual' (year-by-year returns)\n",
    "        years: Number of years for the period (required if return_type='cumulative')\n",
    "    \n",
    "    Returns:\n",
    "        Analysis showing both annualized (CAGR) and cumulative returns for comparison\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Add .csv extension if not present\n",
    "        if not filename.endswith('.csv'):\n",
    "            filename += '.csv'\n",
    "        \n",
    "        # Construct full path\n",
    "        filepath = os.path.join('data', 'returns', filename)\n",
    "        \n",
    "        # Check if file exists\n",
    "        if not os.path.exists(filepath):\n",
    "            return f\"Error: File '{filename}' not found in data/returns folder.\"\n",
    "        \n",
    "        # Load the CSV\n",
    "        df = pd.read_csv(filepath)\n",
    "        \n",
    "        # Validate return column exists\n",
    "        if return_column not in df.columns:\n",
    "            return f\"Error: Column '{return_column}' not found. Available columns: {', '.join(df.columns.tolist())}\"\n",
    "        \n",
    "        # Normalize return_type\n",
    "        return_type = return_type.lower().strip()\n",
    "        \n",
    "        if return_type == 'cumulative':\n",
    "            if years is None or years <= 0:\n",
    "                return \"Error: 'years' parameter is required and must be positive when return_type='cumulative'\"\n",
    "            \n",
    "            # Parse cumulative returns (handle % strings)\n",
    "            def parse_return(val):\n",
    "                if pd.isna(val):\n",
    "                    return None\n",
    "                if isinstance(val, (int, float)):\n",
    "                    return float(val) / 100 if val > 1 else float(val)\n",
    "                # String with %\n",
    "                str_val = str(val).strip().replace('%', '').replace(',', '')\n",
    "                try:\n",
    "                    num = float(str_val)\n",
    "                    return num / 100 if num > 1 else num\n",
    "                except:\n",
    "                    return None\n",
    "            \n",
    "            df['parsed_return'] = df[return_column].apply(parse_return)\n",
    "            df = df.dropna(subset=['parsed_return'])\n",
    "            \n",
    "            # Calculate CAGR: (1 + total_return)^(1/years) - 1\n",
    "            df['CAGR'] = ((1 + df['parsed_return']) ** (1.0 / years)) - 1\n",
    "            df['cumulative_return'] = df['parsed_return']\n",
    "            \n",
    "            # Format results\n",
    "            result_parts = [f\"Analysis of {filename} (Cumulative {years}-Year Returns):\\n\"]\n",
    "            result_parts.append(f\"{'Investment':<40} {'Cumulative Return':>18} {'CAGR (Annual)':>18}\")\n",
    "            result_parts.append(\"-\" * 80)\n",
    "            \n",
    "            for idx, row in df.head(15).iterrows():\n",
    "                name = row.get('Name', row.get('Symbol', f'Row {idx}'))[:38]\n",
    "                cum_ret = f\"{row['cumulative_return']*100:.2f}%\"\n",
    "                cagr = f\"{row['CAGR']*100:.2f}%\"\n",
    "                result_parts.append(f\"{name:<40} {cum_ret:>18} {cagr:>18}\")\n",
    "            \n",
    "            result_parts.append(f\"\\nüìä Summary Statistics:\")\n",
    "            result_parts.append(f\"  - Average Cumulative Return: {df['cumulative_return'].mean()*100:.2f}%\")\n",
    "            result_parts.append(f\"  - Average CAGR: {df['CAGR'].mean()*100:.2f}%\")\n",
    "            result_parts.append(f\"  - Best CAGR: {df['CAGR'].max()*100:.2f}%\")\n",
    "            \n",
    "        elif return_type == 'annual':\n",
    "            # Parse annual returns\n",
    "            def parse_return(val):\n",
    "                if pd.isna(val):\n",
    "                    return None\n",
    "                if isinstance(val, (int, float)):\n",
    "                    return float(val) / 100 if abs(val) > 1 else float(val)\n",
    "                str_val = str(val).strip().replace('%', '').replace(',', '')\n",
    "                try:\n",
    "                    num = float(str_val)\n",
    "                    return num / 100 if abs(num) > 1 else num\n",
    "                except:\n",
    "                    return None\n",
    "            \n",
    "            df['parsed_return'] = df[return_column].apply(parse_return)\n",
    "            df = df.dropna(subset=['parsed_return'])\n",
    "            \n",
    "            # Calculate compound return: product of (1 + r) for each year, minus 1\n",
    "            cumulative = 1.0\n",
    "            returns_list = df['parsed_return'].tolist()\n",
    "            for r in returns_list:\n",
    "                cumulative *= (1 + r)\n",
    "            cumulative_return = cumulative - 1\n",
    "            \n",
    "            # Calculate CAGR\n",
    "            n_years = len(returns_list)\n",
    "            cagr = (cumulative ** (1.0 / n_years)) - 1 if n_years > 0 else 0\n",
    "            \n",
    "            result_parts = [f\"Analysis of {filename} (Annual Returns):\\n\"]\n",
    "            result_parts.append(f\"{'Year':<10} {'Annual Return':>15}\")\n",
    "            result_parts.append(\"-\" * 30)\n",
    "            \n",
    "            for idx, row in df.iterrows():\n",
    "                year = row.get('Year', row.get('Date', f'Period {idx}'))\n",
    "                annual_ret = f\"{row['parsed_return']*100:.2f}%\"\n",
    "                result_parts.append(f\"{str(year):<10} {annual_ret:>15}\")\n",
    "            \n",
    "            result_parts.append(f\"\\nüìä Summary Statistics:\")\n",
    "            result_parts.append(f\"  - Number of Years: {n_years}\")\n",
    "            result_parts.append(f\"  - Cumulative Return ({n_years} years): {cumulative_return*100:.2f}%\")\n",
    "            result_parts.append(f\"  - CAGR: {cagr*100:.2f}%\")\n",
    "            result_parts.append(f\"  - Average Annual Return: {df['parsed_return'].mean()*100:.2f}%\")\n",
    "            result_parts.append(f\"  - Best Year: {df['parsed_return'].max()*100:.2f}%\")\n",
    "            result_parts.append(f\"  - Worst Year: {df['parsed_return'].min()*100:.2f}%\")\n",
    "            \n",
    "        else:\n",
    "            return f\"Error: return_type must be either 'cumulative' or 'annual', got '{return_type}'\"\n",
    "        \n",
    "        return '\\n'.join(result_parts)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error calculating comparable returns: {str(e)}\"\n",
    "\n",
    "tools = [load_returns_csv, standardize_percent_representations, calculate_comparable_returns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Financial Analysis Agent created with middleware!\n"
     ]
    }
   ],
   "source": [
    "# Create the Claude model for our agent\n",
    "claude_model = ChatAnthropic(model=\"claude-sonnet-4-20250514\", temperature=0)\n",
    "\n",
    "\n",
    "@after_model\n",
    "def log_after_model(state, runtime):\n",
    "    \"\"\"Called after each model invocation.\"\"\"\n",
    "    last_message = state.get(\"messages\", [])[-1] if state.get(\"messages\") else None\n",
    "    if last_message:\n",
    "        has_tool_calls = hasattr(last_message, 'tool_calls') and last_message.tool_calls\n",
    "        print(f\"[LOG] After model - Tool calls requested: {has_tool_calls}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# Create the financial analysis agent with middleware\n",
    "financial_agent = create_agent(\n",
    "    model=claude_model,\n",
    "    tools=tools,\n",
    "    system_prompt=\"\"\"You are a helpful financial analysis assistant with access to historical return data for various investments.\n",
    "\n",
    "Your role is to:\n",
    "1. Help users analyze investment returns and performance data\n",
    "2. Load CSV files with historical return data when requested\n",
    "3. Standardize percent representations to float format when needed\n",
    "4. Provide accurate calculations and insights based on the data\n",
    "5. Be professional and informative in your responses\n",
    "6. Always remind users that this is for educational purposes only and not investment advice\n",
    "\n",
    "Remember: Use the available tools to access and analyze the data.\"\"\",\n",
    "    middleware=[\n",
    "        log_after_model\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Financial Analysis Agent created with middleware!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: what were the VFIAX returns like for the last 5 years\n",
      "\n",
      "================================================================================\n",
      "[LOG] After model - Tool calls requested: [{'name': 'load_returns_csv', 'args': {'filename': 'vfiax_returns_2011_2025.csv'}, 'id': 'toolu_01HWkfEjD5yPpSw7GTSTFm6a', 'type': 'tool_call'}]\n",
      "[LOG] After model - Tool calls requested: [{'name': 'load_returns_csv', 'args': {'filename': 'vfiax_returns_2011_2025'}, 'id': 'toolu_01Te6CuTkGZ23wrrxmkDTQWU', 'type': 'tool_call'}]\n",
      "[LOG] After model - Tool calls requested: [{'name': 'load_returns_csv', 'args': {'filename': 'vfiax_returns_2011_2025.csv'}, 'id': 'toolu_01KKsTzuyq83LZg229gjwEwc', 'type': 'tool_call'}]\n",
      "[LOG] After model - Tool calls requested: []\n",
      "\n",
      "================================================================================\n",
      "Agent Response:\n",
      "I apologize, but I'm experiencing a technical issue accessing the VFIAX returns file, even though it appears to be listed as available. This might be a temporary system issue.\n",
      "\n",
      "However, I can provide you with some general context about VFIAX performance over the last 5 years (2020-2024):\n",
      "\n",
      "**VFIAX (Vanguard S&P 500 Index Fund) Recent Performance Context:**\n",
      "\n",
      "VFIAX tracks the S&P 500 index, so its performance closely mirrors the broader U.S. stock market. The last 5 years have included:\n",
      "\n",
      "- **2020**: Significant volatility due to COVID-19, but strong recovery\n",
      "- **2021**: Strong bull market performance \n",
      "- **2022**: Challenging year with inflation concerns and rate hikes\n",
      "- **2023**: Recovery and growth\n",
      "- **2024**: Continued market strength\n",
      "\n",
      "Since VFIAX has very low fees (expense ratio around 0.04%) and tracks the S&P 500, its returns would be very close to the overall S&P 500 performance during this period.\n",
      "\n",
      "Would you like me to try loading the S&P 500 data instead, which would give you a very close approximation of VFIAX performance? Or if you have access to the specific VFIAX data in a different format, I'd be happy to help analyze that.\n",
      "\n",
      "**Disclaimer**: This information is for educational purposes only and should not be considered investment advice.\n",
      "\n",
      "================================================================================\n",
      "Total model calls made: 1\n"
     ]
    }
   ],
   "source": [
    "# Test the financial analysis agent\n",
    "query = (\"Compare the S&P500, VFIAX and ETF return files in the data/returns folder \"\n",
    "         \"to determine which strategy would produce the best returns for $10,000 invested in 2020\")\n",
    "\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "result = financial_agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": query}]})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"Agent Response:\\n{result['messages'][-1].content}\")\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"Total model calls made: {model_call_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Compare the S&P500, VFIAX and ETF return files in the data/returns folder to determine which type of fund had the best returns in the last 5 yars: S&P500 Index Fund, any ETF fund, VFIAX mutual fund\n",
      "\n",
      "================================================================================\n",
      "[LOG] After model - Tool calls requested: [{'name': 'load_returns_csv', 'args': {'filename': 'sp500_returns_1928_2025.csv'}, 'id': 'toolu_015urzAYVyoanq17zcjBVVJb', 'type': 'tool_call'}, {'name': 'load_returns_csv', 'args': {'filename': 'vfiax_returns_2011_2025.csv'}, 'id': 'toolu_01NtNE2eosNVTzgv1YaCXxr7', 'type': 'tool_call'}, {'name': 'load_returns_csv', 'args': {'filename': 'top_etf_returns_2020_2025.csv'}, 'id': 'toolu_01C5C1Sn6vdBJfUYeganuGJD', 'type': 'tool_call'}]\n",
      "[LOG] After model - Tool calls requested: [{'name': 'standardize_percent_representations', 'args': {'filename': 'vfiax_returns_2011_2025.csv', 'column_names': 'Capital return by NAV,Income return by NAV,Total return by NAV,Benchmark'}, 'id': 'toolu_017P8ThTzEcTP4qs8dHyJSZf', 'type': 'tool_call'}, {'name': 'standardize_percent_representations', 'args': {'filename': 'top_etf_returns_2020_2025.csv', 'column_names': '5-Year Return'}, 'id': 'toolu_01PeShy2z9PDiEqPbZTQsxMa', 'type': 'tool_call'}]\n",
      "[LOG] After model - Tool calls requested: [{'name': 'calculate_comparable_returns', 'args': {'filename': 'vfiax_returns_2011_2025.csv', 'return_column': 'Total return by NAV', 'return_type': 'annual'}, 'id': 'toolu_013jCvK9dYg2kPQEpNUJLZEg', 'type': 'tool_call'}, {'name': 'calculate_comparable_returns', 'args': {'filename': 'top_etf_returns_2020_2025.csv', 'return_column': '5-Year Return', 'return_type': 'cumulative', 'years': 5}, 'id': 'toolu_011n7cJ2ZBNQpFgbDey6hVbH', 'type': 'tool_call'}]\n",
      "[LOG] After model - Tool calls requested: [{'name': 'calculate_comparable_returns', 'args': {'filename': 'sp500_returns_1928_2025.csv', 'return_column': 'Value', 'return_type': 'annual'}, 'id': 'toolu_01PUrFFxqHYNPDjD6SEC2Dbb', 'type': 'tool_call'}]\n",
      "[LOG] After model - Tool calls requested: []\n",
      "\n",
      "================================================================================\n",
      "Agent Response:\n",
      "## üìä **5-Year Investment Performance Comparison (2020-2025)**\n",
      "\n",
      "Based on my analysis of the three datasets, here's how each investment type performed over the last 5 years:\n",
      "\n",
      "### **üèÜ Performance Rankings:**\n",
      "\n",
      "**1. VFIAX Mutual Fund (S&P 500 Index Fund) - WINNER**\n",
      "- **5-Year CAGR**: ~13.8%\n",
      "- **5-Year Cumulative Return**: ~95.4%\n",
      "- **Years analyzed**: 2021-2025 (2020: 18.37%, 2021: 28.66%, 2022: -18.15%, 2023: 26.24%, 2024: 24.97%, 2025: 17.83%)\n",
      "\n",
      "**2. S&P 500 Index**\n",
      "- **5-Year CAGR**: ~13.7%\n",
      "- **5-Year Cumulative Return**: ~94.8%\n",
      "- **Years analyzed**: 2021-2025 (2020: 16.26%, 2021: 26.89%, 2022: -19.44%, 2023: 24.23%, 2024: 23.31%, 2025: 16.39%)\n",
      "\n",
      "**3. Top ETFs (Average Performance)**\n",
      "- **Average 5-Year CAGR**: 4.36%\n",
      "- **Best ETF CAGR**: 8.59% (ProShares Ultra Semiconductors)\n",
      "- **Average 5-Year Cumulative Return**: 23.85%\n",
      "\n",
      "### **üîç Key Insights:**\n",
      "\n",
      "1. **VFIAX slightly outperformed** the S&P 500 index due to its active management and dividend reinvestment structure.\n",
      "\n",
      "2. **Both VFIAX and S&P 500** significantly outperformed the average ETF, delivering roughly **3x better returns**.\n",
      "\n",
      "3. **ETF Performance was highly variable** - while the best ETF (Ultra Semiconductors) achieved 8.59% CAGR, the average was much lower at 4.36%.\n",
      "\n",
      "4. **Consistency matters** - Both VFIAX and S&P 500 showed similar patterns with strong years (2021, 2023-2024) and one challenging year (2022).\n",
      "\n",
      "### **üéØ Conclusion:**\n",
      "**VFIAX (S&P 500 Index Mutual Fund) had the best returns** over the last 5 years, followed very closely by the S&P 500 index itself. The broad market index approach significantly outperformed specialized ETFs on average.\n",
      "\n",
      "---\n",
      "*‚ö†Ô∏è This analysis is for educational purposes only and should not be considered investment advice. Past performance does not guarantee future results.*\n",
      "\n",
      "================================================================================\n",
      "Total model calls made: 1\n"
     ]
    }
   ],
   "source": [
    "# Test the financial analysis agent\n",
    "query = (\"Compare the S&P500, VFIAX and ETF return files in the data/returns folder \"\n",
    "         \"to determine which type of fund had the best returns in the last 5 yars: \"\n",
    "         \"S&P500 Index Fund, any ETF fund, VFIAX mutual fund\")\n",
    "\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "result = financial_agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": query}]})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"Agent Response:\\n{result['messages'][-1].content}\")\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"Total model calls made: {model_call_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "03-the-agent-loop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 7: Synthetic Data Generation and RAG Evaluation with Ragas\n",
    "\n",
    "In this notebook, we'll go end-to-end from **generating synthetic evaluation data** to **systematically evaluating and improving a RAG pipeline** ‚Äî all using [Ragas](https://github.com/explodinggradients/ragas).\n",
    "\n",
    "The flow is:\n",
    "1. **Generate** synthetic test data using Ragas' knowledge graph-based approach\n",
    "2. **Build** a baseline RAG application with LangChain and LangGraph\n",
    "3. **Evaluate** the RAG application against our synthetic test set using Ragas metrics\n",
    "4. **Iterate** on the pipeline and measure the impact\n",
    "\n",
    "> **NOTE:** Ragas is framework-agnostic ‚Äî while this example uses LangChain/LangGraph, you can use Ragas with any framework (or none at all). Ragas is best suited for finding *directional* changes in your LLM-based systems. The absolute scores aren't comparable in a vacuum.\n",
    "\n",
    "## Outline\n",
    "\n",
    "**Part 1: Synthetic Data Generation**\n",
    "- Task 1: Dependencies and API Keys\n",
    "- Task 2: Data Preparation\n",
    "- Task 3: Knowledge Graph Construction\n",
    "- Task 4: Generating Synthetic Test Data\n",
    "- ***‚ùì Question #1 & Question #2***\n",
    "- ***üèóÔ∏è Activity #1: Custom Query Distribution***\n",
    "\n",
    "**Part 2: RAG Evaluation with Ragas**\n",
    "- Task 5: Building a Baseline RAG Application\n",
    "- Task 6: Evaluating with Ragas\n",
    "- Task 7: Making Adjustments and Re-Evaluating\n",
    "- ***‚ùì Question #3, Question #4, Question #5, & Question #6***\n",
    "- ***üèóÔ∏è Activity #2: Implement a Different Reranking Strategy***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Synthetic Data Generation with Ragas\n",
    "\n",
    "Before we can evaluate a RAG system, we need high-quality test data. Manually creating question-answer pairs is time-consuming and often biased toward simple queries. Ragas solves this by building a **knowledge graph** from your documents and using it to generate diverse, realistic test questions automatically.\n",
    "\n",
    "We'll use the **Stone Ridge 2025 Investor Letter** and an **Alternative Investments Handbook** as our source documents ‚Äî maintaining continuity with the investment advisory use case from previous sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Dependencies and API Keys\n",
    "\n",
    "If you have not already done so, install the required libraries using the uv package manager:\n",
    "```bash\n",
    "uv sync\n",
    "```\n",
    "\n",
    "We'll need API keys for:\n",
    "- **OpenAI** ‚Äî for LLM and embedding models (used in both SDG and RAG evaluation)\n",
    "- **Cohere** ‚Äî for reranking in the improved pipeline ([sign up here](https://docs.cohere.com/reference/about))\n",
    "\n",
    "You have two options for supplying your API keys:\n",
    "- Use environment variables (copy `.env.sample` to `.env` and fill in your keys)\n",
    "- Provide them via the prompts below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     Basic Constraints of CA cert not marked critical\n",
      "[nltk_data]     (_ssl.c:1028)>\n",
      "[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\n",
      "[nltk_data]     [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify\n",
      "[nltk_data]     failed: Basic Constraints of CA cert not marked\n",
      "[nltk_data]     critical (_ssl.c:1028)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Please enter your OpenAI API key!\")\n",
    "\n",
    "if not os.environ.get(\"COHERE_API_KEY\"):\n",
    "    os.environ[\"COHERE_API_KEY\"] = getpass(\"Please enter your Cohere API key!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Data Preparation\n",
    "\n",
    "We'll prepare our data using two complementary investment-focused sources:\n",
    "- **Stone Ridge 2025 Investor Letter** ‚Äî covering Stone Ridge's investment philosophy, Bayesian approach to decision-making, energy investments, reinsurance, and risk management\n",
    "- **Alternative Investments Handbook** ‚Äî covering alternative asset classes including real estate, private equity, hedge funds, reinsurance, commodities, and infrastructure\n",
    "\n",
    "The topical overlap between these documents (particularly around reinsurance, risk premiums, diversification, and alternative investments) helps Ragas build rich cross-document relationships in the knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 15 documents:\n",
      "  - Stone Ridge 2025 Investor Letter: 14 pages\n",
      "  - AlternativeInvestmentsHandbook.txt: 1 document(s)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader, TextLoader\n",
    "\n",
    "# Load the Stone Ridge 2025 Investor Letter (PDF)\n",
    "pdf_loader = PyMuPDFLoader(\"data/Stone Ridge 2025 Investor Letter.pdf\")\n",
    "pdf_docs = pdf_loader.load()\n",
    "\n",
    "# Load the Alternative Investments Handbook (text)\n",
    "txt_loader = TextLoader(\"data/AlternativeInvestmentsHandbook.txt\")\n",
    "txt_docs = txt_loader.load()\n",
    "\n",
    "# Combine into a single list\n",
    "docs = pdf_docs + txt_docs\n",
    "print(f\"Loaded {len(docs)} documents:\")\n",
    "print(f\"  - Stone Ridge 2025 Investor Letter: {len(pdf_docs)} pages\")\n",
    "print(f\"  - AlternativeInvestmentsHandbook.txt: {len(txt_docs)} document(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Knowledge Graph Construction\n",
    "\n",
    "Ragas uses a **knowledge graph-based approach** to create synthetic test data. This is powerful because it allows us to create complex, multi-hop queries ‚Äî not just simple factoid questions. Systems tend to perform well on simple evaluation tasks, so this additional complexity helps us find real weaknesses.\n",
    "\n",
    "The process works in three stages:\n",
    "1. **Build the graph** ‚Äî insert documents as nodes\n",
    "2. **Apply transformations** ‚Äî extract headlines, summaries, themes, entities, and embeddings\n",
    "3. **Create relationships** ‚Äî use cosine similarity and overlap scores to connect related nodes\n",
    "\n",
    "Let's start by defining our `generator_llm` and `generator_embeddings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexei.naumann/Desktop/AIE/AI-Engineering/07_Synthetic_Data_and_Evaluation/.venv/lib/python3.13/site-packages/pysbd/segmenter.py:66: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  for match in re.finditer('{0}\\s*'.format(re.escape(sent)), self.original_text):\n",
      "/Users/alexei.naumann/Desktop/AIE/AI-Engineering/07_Synthetic_Data_and_Evaluation/.venv/lib/python3.13/site-packages/pysbd/lang/arabic.py:29: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  txt = re.sub('(?<={0})\\.'.format(am), '‚àØ', txt)\n",
      "/Users/alexei.naumann/Desktop/AIE/AI-Engineering/07_Synthetic_Data_and_Evaluation/.venv/lib/python3.13/site-packages/pysbd/lang/persian.py:29: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  txt = re.sub('(?<={0})\\.'.format(am), '‚àØ', txt)\n"
     ]
    }
   ],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-nano\"))\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Initialize the Knowledge Graph\n",
    "\n",
    "We create an empty knowledge graph and populate it with our document nodes. Each full document becomes a node of type `DOCUMENT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 15, relationships: 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset.graph import KnowledgeGraph, Node, NodeType\n",
    "\n",
    "kg = KnowledgeGraph()\n",
    "\n",
    "for doc in docs:\n",
    "    kg.nodes.append(\n",
    "        Node(\n",
    "            type=NodeType.DOCUMENT,\n",
    "            properties={\"page_content\": doc.page_content, \"document_metadata\": doc.metadata}\n",
    "        )\n",
    "    )\n",
    "kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Apply Transformations\n",
    "\n",
    "Now we apply the [default transformations](https://docs.ragas.io/en/latest/references/transforms/#ragas.testset.transforms.default_transforms) to enrich our knowledge graph. These transformations:\n",
    "\n",
    "- **HeadlinesExtractor** ‚Äî finds the overall headlines for each document\n",
    "- **SummaryExtractor** ‚Äî produces summaries of the documents\n",
    "- **ThemesExtractor** ‚Äî extracts broad themes\n",
    "- **EmbeddingExtractor** ‚Äî creates embeddings for similarity computation\n",
    "- **NERExtractor** ‚Äî extracts named entities\n",
    "\n",
    "These are then used to build relationships between nodes via cosine similarity and overlap scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a43073fcc04c497ca35630ed6c2752c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlinesExtractor:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed1ab65229c9446c9201305d111e8ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlineSplitter:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to apply transformation: 'headlines' property not found in this node\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f22f5cdaf3a4f7ebcfb42b9ea68babe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'summary' already exists in node '132413'. Skipping!\n",
      "Property 'summary' already exists in node 'a76a82'. Skipping!\n",
      "Property 'summary' already exists in node '697b0a'. Skipping!\n",
      "Property 'summary' already exists in node '44a429'. Skipping!\n",
      "Property 'summary' already exists in node '35fe94'. Skipping!\n",
      "Property 'summary' already exists in node '9cb6a7'. Skipping!\n",
      "Property 'summary' already exists in node '146f6b'. Skipping!\n",
      "Property 'summary' already exists in node '68adf1'. Skipping!\n",
      "Property 'summary' already exists in node 'ac02b0'. Skipping!\n",
      "Property 'summary' already exists in node '8f6ea5'. Skipping!\n",
      "Property 'summary' already exists in node '6c6749'. Skipping!\n",
      "Property 'summary' already exists in node 'd48a73'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e3d36b3649f4d3f9aef49cb9ece3443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a0187890a34281abb6af023332bc12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'summary_embedding' already exists in node '132413'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'a76a82'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '697b0a'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '68adf1'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'ac02b0'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '44a429'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '9cb6a7'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '146f6b'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '35fe94'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'd48a73'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '8f6ea5'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '6c6749'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c43fe81e98a045b8bb6a7dd54c6b9481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 35, relationships: 330)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset.transforms import default_transforms, apply_transforms\n",
    "\n",
    "transforms = default_transforms(\n",
    "    documents=docs,\n",
    "    llm=generator_llm,\n",
    "    embedding_model=generator_embeddings\n",
    ")\n",
    "apply_transforms(kg, transforms)\n",
    "kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Save the Knowledge Graph\n",
    "\n",
    "Knowledge graphs can be saved and loaded, which is useful for iterating on test generation without rebuilding the graph each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.save(\"investment_data_kg.json\")\n",
    "\n",
    "# You can reload it later:\n",
    "# kg = KnowledgeGraph.load(\"investment_data_kg.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Generating Synthetic Test Data\n",
    "\n",
    "With our knowledge graph built, we can now generate synthetic test data. Ragas provides several **query synthesizers**, each producing a different type of question:\n",
    "\n",
    "- **`SingleHopSpecificQuerySynthesizer`** ‚Äî creates questions answerable from a single chunk of context (e.g., *\"What is Stone Ridge's approach to reinsurance investing?\"*)\n",
    "- **`MultiHopAbstractQuerySynthesizer`** ‚Äî creates questions requiring synthesis across multiple chunks at an abstract level (e.g., *\"How do alternative risk premiums relate to portfolio diversification?\"*)\n",
    "- **`MultiHopSpecificQuerySynthesizer`** ‚Äî creates questions requiring specific details from multiple chunks (e.g., *\"How does Stone Ridge's Bayesian philosophy connect to their energy investment strategy?\"*)\n",
    "\n",
    "We define a **query distribution** to control the mix of question types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.synthesizers import (\n",
    "    SingleHopSpecificQuerySynthesizer,\n",
    "    MultiHopAbstractQuerySynthesizer,\n",
    "    MultiHopSpecificQuerySynthesizer,\n",
    ")\n",
    "\n",
    "query_distribution = [\n",
    "    (SingleHopSpecificQuerySynthesizer(llm=generator_llm), 0.5),\n",
    "    (MultiHopAbstractQuerySynthesizer(llm=generator_llm), 0.25),\n",
    "    (MultiHopSpecificQuerySynthesizer(llm=generator_llm), 0.25),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df5c612849841668ab603b3a8d90c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b480cf3a4c4d428e1f48dad52c0c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e202c81a34fc4396933bfdce0aa339ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the date 9/30/2025?</td>\n",
       "      <td>[Standardized returns as of most recent quarte...</td>\n",
       "      <td>Standardized returns as of most recent quarter...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is Stone Ridge known for in the context o...</td>\n",
       "      <td>[Risk Disclosures This communication has been ...</td>\n",
       "      <td>The provided context does not specify what Sto...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is reinsurance?</td>\n",
       "      <td>[The Alternative Investments Handbook A Practi...</td>\n",
       "      <td>Reinsurance is included among alternative inve...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What does the cap rate indicate in real estate...</td>\n",
       "      <td>[PART 2: REAL ESTATE INVESTMENTS Chapter 4: Re...</td>\n",
       "      <td>The cap rate, or capitalization rate, is calcu...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is Series B in venture capital?</td>\n",
       "      <td>[Chapter 7: Venture Capital Venture capital (V...</td>\n",
       "      <td>Series B and beyond are later rounds for compa...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How do the characteristics of infrastructure i...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nThe Alternative Investments Handbo...</td>\n",
       "      <td>Infrastructure investments provide stable, pre...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wht are the investment performnce metrics and ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nStandardized returns as of most re...</td>\n",
       "      <td>The investment performance metrics, such as th...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How does real estate contribute to portfolio d...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nThe Alternative Investments Handbo...</td>\n",
       "      <td>Real estate contributes to portfolio diversifi...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Considering the insights from PART 2 on real e...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nPART 5: INSURANCE-LINKED INVESTMEN...</td>\n",
       "      <td>Integrating catastrophe risk modeling and rein...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What hedge fund strategies are discussed in th...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nThe Alternative Investments Handbo...</td>\n",
       "      <td>The context discusses various hedge fund strat...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How does the information in Chapter 13 about c...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nPART 6: COMMODITIES AND REAL ASSET...</td>\n",
       "      <td>Chapter 13 explains that commodities serve as ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0                         What is the date 9/30/2025?   \n",
       "1   What is Stone Ridge known for in the context o...   \n",
       "2                                What is reinsurance?   \n",
       "3   What does the cap rate indicate in real estate...   \n",
       "4                What is Series B in venture capital?   \n",
       "5   How do the characteristics of infrastructure i...   \n",
       "6   Wht are the investment performnce metrics and ...   \n",
       "7   How does real estate contribute to portfolio d...   \n",
       "8   Considering the insights from PART 2 on real e...   \n",
       "9   What hedge fund strategies are discussed in th...   \n",
       "10  How does the information in Chapter 13 about c...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [Standardized returns as of most recent quarte...   \n",
       "1   [Risk Disclosures This communication has been ...   \n",
       "2   [The Alternative Investments Handbook A Practi...   \n",
       "3   [PART 2: REAL ESTATE INVESTMENTS Chapter 4: Re...   \n",
       "4   [Chapter 7: Venture Capital Venture capital (V...   \n",
       "5   [<1-hop>\\n\\nThe Alternative Investments Handbo...   \n",
       "6   [<1-hop>\\n\\nStandardized returns as of most re...   \n",
       "7   [<1-hop>\\n\\nThe Alternative Investments Handbo...   \n",
       "8   [<1-hop>\\n\\nPART 5: INSURANCE-LINKED INVESTMEN...   \n",
       "9   [<1-hop>\\n\\nThe Alternative Investments Handbo...   \n",
       "10  [<1-hop>\\n\\nPART 6: COMMODITIES AND REAL ASSET...   \n",
       "\n",
       "                                            reference  \\\n",
       "0   Standardized returns as of most recent quarter...   \n",
       "1   The provided context does not specify what Sto...   \n",
       "2   Reinsurance is included among alternative inve...   \n",
       "3   The cap rate, or capitalization rate, is calcu...   \n",
       "4   Series B and beyond are later rounds for compa...   \n",
       "5   Infrastructure investments provide stable, pre...   \n",
       "6   The investment performance metrics, such as th...   \n",
       "7   Real estate contributes to portfolio diversifi...   \n",
       "8   Integrating catastrophe risk modeling and rein...   \n",
       "9   The context discusses various hedge fund strat...   \n",
       "10  Chapter 13 explains that commodities serve as ...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0   single_hop_specifc_query_synthesizer  \n",
       "1   single_hop_specifc_query_synthesizer  \n",
       "2   single_hop_specifc_query_synthesizer  \n",
       "3   single_hop_specifc_query_synthesizer  \n",
       "4   single_hop_specifc_query_synthesizer  \n",
       "5   multi_hop_abstract_query_synthesizer  \n",
       "6   multi_hop_abstract_query_synthesizer  \n",
       "7   multi_hop_abstract_query_synthesizer  \n",
       "8   multi_hop_specific_query_synthesizer  \n",
       "9   multi_hop_specific_query_synthesizer  \n",
       "10  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(\n",
    "    llm=generator_llm,\n",
    "    embedding_model=generator_embeddings,\n",
    "    knowledge_graph=kg\n",
    ")\n",
    "\n",
    "testset = generator.generate(testset_size=10, query_distribution=query_distribution)\n",
    "testset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstracted SDG (Shortcut)\n",
    "\n",
    "The above was the **unrolled** process showing each step. Ragas also provides a one-liner that builds the knowledge graph under the hood and generates the test set in a single call. This is convenient for quick iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abstracted approach (for reference):\n",
    "# generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
    "# dataset = generator.generate_with_langchain_docs(docs, testset_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Question #1:\n",
    "\n",
    "What are the three types of query synthesizers doing? Describe each one in simple terms.\n",
    "\n",
    "##### ‚úÖ Answer:\n",
    "\n",
    "The query synthesizers are taking chunks of the input documents and generating questions based on the contents of the document chunks. They use an LLM to come up with questions about the chunks and also generate answers with sources cited. Having this automatically-generated question-response data set allows you to test the effectiveness of the RAG pipeline you built for retrieving answers. <br><br>\n",
    "The three types of synthesizers are generating questions with differing levels of difficulty and differing quantities of documents required to be processed in answering the questions. THe single hop synthesizer tests the RAG system with questions that only require data from a single document to answer the question. The multi-hop abastract synthesizer generates abstract questions that require multiple documents and a broad understanding about how the data in those documents is related. The multi-hop specific question synthesizer generates questions that require multiple documents to answer and that also require specific details from those documents. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Question #2:\n",
    "\n",
    "Ragas offers both an \"unrolled\" (manual) approach and an \"abstracted\" (automatic) approach to synthetic data generation. What are the trade-offs between these two approaches? When would you choose one over the other?\n",
    "\n",
    "##### ‚úÖ Answer:\n",
    "\n",
    "You need to specify a lot more custom config properties with the manual approach, which ultimately gives you tighter control and a higher degree of customizability over how the test dataset is built. The automatic approach gives you less control in generating synthetic data but, it's easier to use and faster for one-off experiments or rapid iteration. I would use the automatic approach for early-stage RAG evaluation and rapid prototyping and then likely move to the manual approach when I want to test specific factets and connections in my RAG pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üèóÔ∏è Activity #1: Custom Query Distribution\n",
    "\n",
    "Modify the `query_distribution` to experiment with different ratios of query types.\n",
    "\n",
    "**Requirements:**\n",
    "1. Create a custom query distribution with different weights than the default\n",
    "2. Generate a new test set using your custom distribution\n",
    "3. Compare the types of questions generated with the default distribution\n",
    "4. Explain why you chose the weights you did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c5b9e59698424eb5933922cd8b168e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34aa2841e34a4ab9990c3a90a121d263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc7a641a7a04874962a5b18a2768ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can you tell me how Stone Ridge Energy's stand...</td>\n",
       "      <td>[Standardized returns as of most recent quarte...</td>\n",
       "      <td>Standardized returns as of the most recent qua...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can you tell me about Stone Rigde and how it r...</td>\n",
       "      <td>[Risk Disclosures This communication has been ...</td>\n",
       "      <td>The provided context discusses Stone Ridge in ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what are commodities</td>\n",
       "      <td>[The Alternative Investments Handbook A Practi...</td>\n",
       "      <td>Commodities are included in alternative invest...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are private real estate funds?</td>\n",
       "      <td>[PART 2: REAL ESTATE INVESTMENTS Chapter 4: Re...</td>\n",
       "      <td>Private real estate funds are pooled vehicles ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Venture Capital what is it do for invest in ea...</td>\n",
       "      <td>[Chapter 7: Venture Capital Venture capital (V...</td>\n",
       "      <td>Venture capital (VC) is a specialized form of ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How does infrastructure as a long-term investm...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nThe Alternative Investments Handbo...</td>\n",
       "      <td>Infrastructure, as highlighted in the Alternat...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PART 5 reinsurance part and PART 6 commodities...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nPART 5: INSURANCE-LINKED INVESTMEN...</td>\n",
       "      <td>In PART 5, reinsurance is shown as an uncorrel...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hedge fund strategies and hedge fund strategie...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nThe Alternative Investments Handbo...</td>\n",
       "      <td>The context explains that hedge fund strategie...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How do PART 2's insights on reinsurance invest...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nPART 5: INSURANCE-LINKED INVESTMEN...</td>\n",
       "      <td>PART 5 explains that reinsurance investments, ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How do Chapters 2 and 5 of 'The Alternative In...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nThe Alternative Investments Handbo...</td>\n",
       "      <td>Chapter 2 discusses the role of alternative in...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  Can you tell me how Stone Ridge Energy's stand...   \n",
       "1  Can you tell me about Stone Rigde and how it r...   \n",
       "2                               what are commodities   \n",
       "3                What are private real estate funds?   \n",
       "4  Venture Capital what is it do for invest in ea...   \n",
       "5  How does infrastructure as a long-term investm...   \n",
       "6  PART 5 reinsurance part and PART 6 commodities...   \n",
       "7  Hedge fund strategies and hedge fund strategie...   \n",
       "8  How do PART 2's insights on reinsurance invest...   \n",
       "9  How do Chapters 2 and 5 of 'The Alternative In...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [Standardized returns as of most recent quarte...   \n",
       "1  [Risk Disclosures This communication has been ...   \n",
       "2  [The Alternative Investments Handbook A Practi...   \n",
       "3  [PART 2: REAL ESTATE INVESTMENTS Chapter 4: Re...   \n",
       "4  [Chapter 7: Venture Capital Venture capital (V...   \n",
       "5  [<1-hop>\\n\\nThe Alternative Investments Handbo...   \n",
       "6  [<1-hop>\\n\\nPART 5: INSURANCE-LINKED INVESTMEN...   \n",
       "7  [<1-hop>\\n\\nThe Alternative Investments Handbo...   \n",
       "8  [<1-hop>\\n\\nPART 5: INSURANCE-LINKED INVESTMEN...   \n",
       "9  [<1-hop>\\n\\nThe Alternative Investments Handbo...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Standardized returns as of the most recent qua...   \n",
       "1  The provided context discusses Stone Ridge in ...   \n",
       "2  Commodities are included in alternative invest...   \n",
       "3  Private real estate funds are pooled vehicles ...   \n",
       "4  Venture capital (VC) is a specialized form of ...   \n",
       "5  Infrastructure, as highlighted in the Alternat...   \n",
       "6  In PART 5, reinsurance is shown as an uncorrel...   \n",
       "7  The context explains that hedge fund strategie...   \n",
       "8  PART 5 explains that reinsurance investments, ...   \n",
       "9  Chapter 2 discusses the role of alternative in...   \n",
       "\n",
       "                       synthesizer_name  \n",
       "0  single_hop_specifc_query_synthesizer  \n",
       "1  single_hop_specifc_query_synthesizer  \n",
       "2  single_hop_specifc_query_synthesizer  \n",
       "3  single_hop_specifc_query_synthesizer  \n",
       "4  single_hop_specifc_query_synthesizer  \n",
       "5  multi_hop_abstract_query_synthesizer  \n",
       "6  multi_hop_specific_query_synthesizer  \n",
       "7  multi_hop_specific_query_synthesizer  \n",
       "8  multi_hop_specific_query_synthesizer  \n",
       "9  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "modified_query_distribution = [\n",
    "    # hypothetically expect to have my RAG system answering 50% simple fact retrieval questions\n",
    "    (SingleHopSpecificQuerySynthesizer(llm=generator_llm), 0.5),\n",
    "    # don't expect to get too many abstract questions\n",
    "    (MultiHopAbstractQuerySynthesizer(llm=generator_llm), 0.1),\n",
    "    # have the RAG system evaluated for some specific multi-document questions\n",
    "    (MultiHopSpecificQuerySynthesizer(llm=generator_llm), 0.4),\n",
    "]\n",
    "\n",
    "generator = TestsetGenerator(\n",
    "    llm=generator_llm,\n",
    "    embedding_model=generator_embeddings,\n",
    "    knowledge_graph=kg\n",
    ")\n",
    "\n",
    "testset = generator.generate(testset_size=10, query_distribution=modified_query_distribution)\n",
    "testset.to_pandas()\n",
    "\n",
    "# Define a custom query distribution with different weights\n",
    "# Generate a new test set and compare with the default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: RAG Evaluation with Ragas\n",
    "\n",
    "Now that we have our synthetic test data, we can use it to **systematically evaluate** a RAG pipeline. The idea is simple:\n",
    "1. Build a RAG application\n",
    "2. Run our synthetic queries through it\n",
    "3. Score the results using Ragas metrics\n",
    "4. Make changes and measure the impact\n",
    "\n",
    "This gives us a **data-driven approach** to improving our RAG system, rather than relying on vibes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Building a Baseline RAG Application\n",
    "\n",
    "We'll build a deliberately simple (and somewhat bad) RAG pipeline as our **baseline**, so we can clearly see the impact of improvements later.\n",
    "\n",
    "Our baseline uses:\n",
    "- Tiny chunks (50 characters) with no overlap\n",
    "- A small embedding model (`text-embedding-3-small`)\n",
    "- Only 3 retrieved documents\n",
    "- A basic prompt\n",
    "\n",
    "> **NOTE:** We use the same data that our synthetic test set was generated from ‚Äî this is required because the test questions are specifically designed for this investment data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R ‚Äî Retrieval\n",
    "\n",
    "First, we chunk our documents and build a vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2045"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=0)\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "len(split_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Question #3:\n",
    "\n",
    "What is the purpose of the `chunk_overlap` parameter in the `RecursiveCharacterTextSplitter`?\n",
    "\n",
    "##### ‚úÖ Answer:\n",
    "\n",
    "It allows you to adjust thoughts and facts in the input documents that may span multiple chunks. This could happen if a contextual fact is long or takes multiple sentences to elucidate. The higher the chunk overlap, the less chance there is of missing one of these complex thoughts that may span multiple input text chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "client = QdrantClient(\":memory:\")\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=\"baseline_rag\",\n",
    "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"baseline_rag\",\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "_ = vector_store.add_documents(documents=split_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state):\n",
    "    retrieved_docs = retriever.invoke(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A ‚Äî Augmented\n",
    "\n",
    "A simple RAG prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "RAG_PROMPT = \"\"\"\\\n",
    "You are a helpful investment advisory assistant who answers questions based on provided context. You must only use the provided context, and cannot use your own knowledge.\n",
    "\n",
    "### Question\n",
    "{question}\n",
    "\n",
    "### Context\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G ‚Äî Generation\n",
    "\n",
    "We use `gpt-4.1-nano` for generation to avoid using the same model as our judge model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-nano\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = rag_prompt.format_messages(question=state[\"question\"], context=docs_content)\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"response\": response.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the RAG Graph with LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a quick sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The provided context does not include specific information about Stone Ridge's investment philosophy.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"What is Stone Ridge's investment philosophy?\"})\n",
    "response[\"response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With tiny 50-character chunks and only 3 retrieved documents, the baseline likely struggles to provide good answers about Stone Ridge's investment philosophy. That's intentional ‚Äî it gives us room to improve!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Evaluating with Ragas\n",
    "\n",
    "Now we can evaluate our baseline RAG against the synthetic test data we generated in Part 1.\n",
    "\n",
    "First, we run all the synthetic queries through our RAG pipeline to collect responses and retrieved contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_row in testset:\n",
    "    response = graph.invoke({\"question\": test_row.eval_sample.user_input})\n",
    "    test_row.eval_sample.response = response[\"response\"]\n",
    "    test_row.eval_sample.retrieved_contexts = [context.page_content for context in response[\"context\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to an `EvaluationDataset` for smoother evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import EvaluationDataset\n",
    "\n",
    "evaluation_dataset = EvaluationDataset.from_pandas(testset.to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select a **judge model** ‚Äî a separate, capable model that scores the outputs. Using a different model than the generator avoids self-evaluation bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-mini\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Baseline Evaluation\n",
    "\n",
    "We evaluate across six metrics:\n",
    "- **Context Recall** ‚Äî did we retrieve the relevant context?\n",
    "- **Faithfulness** ‚Äî is the answer grounded in the retrieved context?\n",
    "- **Factual Correctness** ‚Äî is the answer factually correct vs. the reference?\n",
    "- **Answer Relevancy** ‚Äî is the answer relevant to the question?\n",
    "- **Context Entity Recall** ‚Äî did we capture the key entities from the reference context?\n",
    "- **Noise Sensitivity** ‚Äî is the answer affected by irrelevant retrieved content?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3fd261f787442b0aee63f8ccbabd91d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[8]: AttributeError('StringIO' object has no attribute 'statements')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context_recall': 0.0833, 'faithfulness': 0.4631, 'factual_correctness': 0.3767, 'answer_relevancy': 0.5616, 'context_entity_recall': 0.2324, 'noise_sensitivity_relevant': 0.0234}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.metrics import (\n",
    "    LLMContextRecall,\n",
    "    Faithfulness,\n",
    "    FactualCorrectness,\n",
    "    ResponseRelevancy,\n",
    "    ContextEntityRecall,\n",
    "    NoiseSensitivity,\n",
    ")\n",
    "from ragas import evaluate, RunConfig\n",
    "\n",
    "custom_run_config = RunConfig(timeout=360)\n",
    "\n",
    "baseline_result = evaluate(\n",
    "    dataset=evaluation_dataset,\n",
    "    metrics=[\n",
    "        LLMContextRecall(),\n",
    "        Faithfulness(),\n",
    "        FactualCorrectness(),\n",
    "        ResponseRelevancy(),\n",
    "        ContextEntityRecall(),\n",
    "        NoiseSensitivity(),\n",
    "    ],\n",
    "    llm=evaluator_llm,\n",
    "    run_config=custom_run_config,\n",
    ")\n",
    "baseline_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Making Adjustments and Re-Evaluating\n",
    "\n",
    "Now that we have a baseline, let's improve the pipeline and measure the impact. We'll make three changes:\n",
    "\n",
    "1. **Larger chunks** (500 characters with 30 overlap instead of 50 with 0 overlap)\n",
    "2. **More documents retrieved** (k=20 instead of k=3)\n",
    "3. **Reranking with Cohere** ‚Äî retrieves 20 documents, then uses Cohere's reranker to select the top 5\n",
    "\n",
    "Reranking is a technique that uses a cross-encoder model (slower but more accurate than embedding similarity) on a smaller subset of candidates to improve retrieval precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved chunking: 202 chunks (vs baseline)\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=30)\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "print(f\"Improved chunking: {len(split_documents)} chunks (vs baseline)\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "client = QdrantClient(\":memory:\")\n",
    "client.create_collection(\n",
    "    collection_name=\"improved_rag\",\n",
    "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"improved_rag\",\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "_ = vector_store.add_documents(documents=split_documents)\n",
    "adjusted_retriever = vector_store.as_retriever(search_kwargs={\"k\": 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.retrievers.contextual_compression import (\n",
    "    ContextualCompressionRetriever,\n",
    ")\n",
    "from langchain_cohere import CohereRerank\n",
    "\n",
    "def retrieve_adjusted(state):\n",
    "    compressor = CohereRerank(model=\"rerank-v3.5\")\n",
    "    compression_retriever = ContextualCompressionRetriever(\n",
    "        base_compressor=compressor,\n",
    "        base_retriever=adjusted_retriever,\n",
    "        search_kwargs={\"k\": 5},\n",
    "    )\n",
    "    retrieved_docs = compression_retriever.invoke(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "class AdjustedState(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    response: str\n",
    "\n",
    "adjusted_graph_builder = StateGraph(AdjustedState).add_sequence([retrieve_adjusted, generate])\n",
    "adjusted_graph_builder.add_edge(START, \"retrieve_adjusted\")\n",
    "adjusted_graph = adjusted_graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKkAAAFNCAIAAAD0FdhYAAAQAElEQVR4nOydB1gURxvHZ/f60as0UcFCxN5bbIjYsGHsXWOLHWOJkmL9PqPG2KJYYtSoMWqMmtiiEns+jbFrFEGliUo/4Li233u3eB5wh17i3Z4389OHZ2/alv+Ud2ZnZ/gMwyAClvARAVeI9vhCtMcXoj2+EO3xhWiPLzatfUZa0Y1z2ZlPFQq5RqNGKmWJ7ihFUdBBpWiK0RS703CMGEbD+sIRopDWpUSiFKIRpWEYCKzRvPLi82mVSlPqAng0rdZoKB5i1CVS0PIyaql0BCKaphmxlOcTJGwc7sHj8ZCtQtlg//5pguy3H17kPFfBpfH4SCShhWIawSNWlAhG0QhkZv8Wu1BarYt/Ulp5mJdKGUTTZQttxFeZBuDxaXUZ7WkegjxneAp9yqUu41U6YopRqZUKVFSoVikgKyDPAHHUxABke9iW9lkvCvd+nVokY5zc6dBmro3C3dE7zqkf0xOuyeQFjIefYMDHlZAtYUPa/7Q2OSVe7hck6j2pIrIv8rOV+9cm52aqm3ZyaxTugWwDW9F+07wE+Dt6YRCyXx7ezDuxPd0zQNhnciCyAWxC++8WPHJy4/e2yUbxrbN5XnyNJi6tunshruFe+9g5D70rCntOsLd6vhw2xcQ7uPAHzKiMOIVGnLJ1foKnP17CA6MXVM3P0Rz5Lg1xCpfaH92WqpQzvSfiJTzL6AVBCdfzs9KLEHdwqX38XwUDZtqE1cMJ1Ro47PkqGXEHZ9p//59HLp48R1cBwpWOg301aubikeeIIzjTPitd1Wm4D8KbSjWlN8/mIY7gRvtfv00VipGXvwThTZcRfkq55nlaIeICbrRPS5D7VrG28LNnz/7555+R+YSHh6ekpCDLIHHiXTqYgbiAG+3lBZrarZyRdblz5w4yn7S0tKysLGQxPHyFz1IUiAs4GNt5llL444qUj5ZXRZbh/Pnz27Ztu337tqenZ926dSdNmgQHjRo1Yn0dHR3j4uJkMtmOHTsuXrz48OFD8G3Tps348ePFYjEEmDlzJrx49fX1hUTGjh27YcMGNiKEWb58OXrbXDmZeeV45rj/WupplAMH5T7p70LaYi+17927N2XKlMaNG+/duxdUvH///ueff450GQL+xsTEgPBwsHv37q1btw4ZMmTlypUQ/sSJE7GxsWwKAoEgXseKFSv69OkDAcARGgtLCA8E1pBoVIgTOJi7UZin5tEUsgzXrl2D4jty5Eiapn18fGrWrAkqlg02ePDgsLCwKlWqsD+vX79+4cKFyZMnI90kgNTU1O3bt7PVgKXx8BByNajOybwdhkKW0r5evXpyuXzq1KlNmzZt3bp1xYoV9bW9IVC4ocL/7LPPoGJQqbTlzt391VwByBPWER7gCXlcvVHhoM4XSXhqi91uSEjIqlWrvLy8Vq9e3atXrwkTJkCZLhsMfKGShwAHDhy4cuXKiBEjDH1FIhGyFi+ec9PBQ5xo7xskVistmNVbtGgB7fqhQ4egpc/JyYE6gC3ZesC83bdvX79+/UB7aBfAJS+PswGWlPuFlKUqwdfAgfYBVR1A+dRHMmQB/vzzT2i54QCKfrdu3aKjo0FX6KcZhlEqlYWFhd7e3uxPhUJx5swZxBHJDwpFHA1xcdO/Fwip63G5yAJADQ/m/f79+6FTfuvWLbDnIRNAhw2qcRD70qVLUMODGVi5cuWDBw8mJydnZ2fPnz8frITc3Nz8/PyyCUJI+AsdAUgNWYDUxEJnD25eanCjvaef8Mk9i7RzYMBDTb5s2TIYjBszZoyDgwO063y+1qQF4//y5ctQE0ChX7x4MVhz0IXr2bNnkyZNJk6cCD87dOgAFn6pBAMCAiIjI9evXw8mArIARfmoSUduZvBxM29HrVZ/MyNx4lccDGjYFKf3Prt7KXfCMm6eAzflHgbOpE683cueILwB4YPqOCCO4Oy7nJ4TfXYuKe8FCdTApexzFqgzoMGmTBjH0GdzdXVFFgBGjaDLYNQLrEUYMDB6SUFBQVu2bDEa69Kvz6DO7TTUF3EEl3M19656kp+tHvZpFaO+/6zf5eTkhCyGqUsqKioyNSQAGQLeIBj1WjMtvnWUR51WbogjOJ6nu2HOw+r1HNv1q4AwY9vCR0IJ3T+ayylrHM/THbsk+O7lvNt/WPAlqQ2yZ8UjlVLDrfDIRr7NWPdxfMNwl6Yduf9cwQrs+O8jkZj3wRTuZyfbyjdZ38yKd/MU9LexrxXfOls+S6B51HATJo6VsaFvMeG5yGWa+u1dm3f1RHbHwdgUGM6qVEMcOdZWPj2zrW+wLx15cfVkNk0j/+qS8EE+YontLlzwhiTdl136NfN5skIgoqMm+br72ND0VFtce+HsgWd/X5bJCzSQCUQOlLMHX+IgEAp5KsOlEniUWv3qp7ZrzRQvsUHpZgewYdnVN2hK+/PlsW7RDap4+QTGIFhx/5yh2KeiD/PKT6OLD6lp2DNqA/B4tFqtoXXrOWij0pRaoSyQMfnZyqICjVqFnD35TTq51WjggmwMW9Rez/mDz5Me5BfkajRq7RIZaoMpjdBqakpqzzDF62HoZHp5Xy+XXkGMXmDdSi26v7olOiiWYketfFoY3YodVPEBU5y7dKt16LQvTgFpF+yg1CqGYrOX7jUVRWtXXoE3NJVqiuu3sZWv7cti09pbmnnz5rVs2bJz584IS7BeZwvGjNlXfHhCtCfaYwnRHl+USiW8f0O4Qso9KfdYQrTHF6I9vhDt8YVojy9Ee3wh2uML0R5fyNgOvpByjy9Ee3wh2uMLae8xRaPR7nBE0xx/ncIh+GqPeYWPiPYIY4j2+ILvzWNu6CFS7hHG4HvzDMP4+fkhjMF4ZIPPT0pKQhiDtfZG1/PBB6I9vhDt8YVojy9Ya69WqxHG4PsmA+mW98S56GOtPebVPt4DW0R7bCHa4wvRHl+I9vhCtMcXoj2+EO3xhWiPL5hrj+O6mvXq1TOcls+ujvr+++9//fXXCCdwHNNt3rw56E2/BI69vLyGDx+OMANH7YcOHerhUWKJ45CQkPr16yPMwLTch4aG6n86Ozv369cP4Qem7/GghtdveB8UFNSiRQuEH5hqX7duXbD44MDBwWHgwIEIS15v5z+5n//gal6RvLQ7uwFFibR0GxCUdEFlky/e4qCkr34rAsPdLUoG0B/rtjVAxt31P0ucWn9Kgyh5eXnXrl8TCATNmjYzHsvgqozeC59GKg0y5as7bfFWHshga45SwdhNG0ylgNDLTT90SZkKUyI8zYgcUOue3jzea3aceY32mz+NLyrQ7gKhLCodzMht6BRhGCNhDAODZa3R7WhC0RSj0T+al9rT2u0p2DDscXGAl4FL5TDDRAxPpD8LMqJo8U9Gu3kKrX2mL09UnvYlTwTwaEqtP4XBpRo+En2mYwOUI57hBZdIQnfe4o09jJ+lBDy+NhG1CrlW4A38uLwNucrTfsPseE9/fsehlRHhHWTXsngvX1GvCSY34jOp/ca58QHVxK162cqGXoR/wL5ViWIp3T+6klFf47bexcPPNGpEhH/XiRjs/yJFacrXuPZPHsjFTlgP9dsHju5CvgBdPZ1p1Ne4wMoCDXqdTUF4JwALUZZl/H2Vce3VGrAnKUR499Hu2GiiGJOK3c5ht4M06mVce5pH4btjon2h1d0s7TVqhtT59oOJckzqfHtHO35jXHzj2usqCkSwByiTQtImwhPl7QXTg/akzrd7KMpEHW683MMLJYy3RrcvtLqb094T7IZyyrCp9h6Z7BkQ3inYeSFGvcop98Tcswd05d54MaZNR+CGHr3Ctm3fhGyS03En2oU1ys7OQhxd54hRfVd+/R9kHibF5GCuZmLiw/4Du5ny7dd3SJ3a78BU+X95nb2iwlPTUpA1MNlf58DW+/v+nXJ8Bw4Yjt4F/s11Pn2axlYe1sB0023S1jO3tYc6cN++XVOmfQi1Ym5eLrgcPXZowsThnbu2gr979+1ke43fbl3/36VfpKc/hWA/7v0+ISEeDi5dOtenb6fRYwagknXp7ds3Zs6a2L1HuyHDeq/75qv8/HxwvHzlEkS5deu6/tR3793WJvLHeVNRykcmk8FVjf9oGFzq4CE9IZZc/mpW8voNX/fu0xHcIYzhh5v669z9wzaIqHdnb+38+d+RblgFbvzDMQM7dWk5dtzgjZvWqNXqv65dGTAoEnwHDe4x79NopFvNfUPsKqjPu0a2njVnMjwNfWqPHiWMGz8E0p8zd+rdu7eQ+VD6P2Wgy4tiDgKB4PCvP1WtWuPLpWulEulvJ4+CxtWrhezccXD0qI/gEaxZtxyCjRg+rn+/oRUq+Jw+eeWDPoPY3Qu27dgEVWj09HmGCSanJM2YOUFeJF+z+tsFXyxLSHgwbfoYeEwN6jd2cnQ6c/aUPuS5c6fBpXGjZqailH/l+3/avXPXVriAxYtWjh07Je73E99ti2W9fj649+eDP06ZPGvdum2+vv7btm9E5rB//+4d32/pEzVw987DkZFRv/x6ADJK/XqNlixaCb7f7/h54XztM1m1eik8n149++38/lCb1mGffTHz9zMnkW53h1lzJnl5Vdi6Ze/YDydD3IyMF8hMGNP9NVO2ntnWHgwDOzu7TPpoRqOGTfl8/q+/HqhTp/7UKbPd3NxBrRHDxh04sCcrK7NsLPgLskE+eC8k1NDrt9+OCPgCkDAwsHLlykEzomMexP997nwcj8dr167jmbMn9SEhH4SFdQJ3U1HKv/K+HwzeFLurbZsOoMr7rdq1a9vxf5cvsF6QLdq07gB6ODs5d4qIhBtB5nD9xtUaNWpGRHRzdXXr1rXX2jVbmzZpWSpMUVHRseOHoQXpHhnl4uzSpXOPsPad2EwG9/XsWfpHE6KhqMDtTJ40UybLQ2ZClfo4wYC3aevVqF6TPdBoNLduX2/cqLneq379xuB44+ZfRiNWr/ZeWcfbt6+HhIS6uLiyP318fP38AtgU2rYNh6r1/oN7SGc5Jic/gedVfpRygLrn8pWL4ycMDY9oBtX1nh93sHkU8n9KShI89FfXWf09ZA61atX9888/ln45H5q/nNwcf7+AqlWrlwpz//5dhUJh+Kzq1W0ITSGEh7OLxWK4C9bdw8PT27sCMhfdNw1Gfd6mrScUCtkDuBmorzZvWQf/DQOULffFEUWiso6Qx+/9fQfEKJFCZgbSPR2oTs6cOQltytlzp728vOEplx+lHGI3roZaCmp7EABK2KbNa3898jO4g60AzbNEItWHFIslyBygtpdKHc5f+B2aP6gLIctC1e3p6YVK3ib8nTRlVKm4cNm5uTmGZwdEIjEyE0bbxzNvTPdfrckAuVUqlXYM79q6dZihu5+vGZO+3T08a9euB/aBoaOLs7ZMQ0sB1T5U5mBJQGMf3qHLa6OYAm7z0OF9IBLUyayLvl51cHCAdqTI4Gu0wsIC9DrUmlfrM9M0DcnCfzDZrl7939Ztsfn5ssULvzIM76HLObyz+QAAEABJREFUCtHT5/r7l/iIwtvbB9rQUmcsKHi96VoKijJpuJt4f08z1L+btxMcXD1PlgctKPsTqoG0tBSzqqzgoGrHT/xSt04D/RoZ8AQDAgLZ4/ZtO4IlBSYxtOifzFnwJlGMAhdWWFjo6enN/oQa68LFM+wxPLQKFXyh44A+KA586Y9zZVMQCITQZut3XnryOFHvdezYYWgmqlQJhoYD/sMD+eXXn0pFD/APFOmqPf2zgtoRciQUHp8KvtDjgPo/KKgquMfH33/x4jkyE/PH9f71BO0PR008fz4OKk9o5m/evDZ/wZzpM8bBkwUvEAPs1XPn4pKSHpeTQp8+gyAu9A7g/iEk9IJGju6XkBjP+oaG1oGcBP0ueC76Jrn8KEaBdgoMwyNHD6akJufkZC9dNr92rXp5ebls57Bd23AwuGA4D4537f7uzp2bZVOoWbM2SAUtOtJ18Hbu3qr3Onnq6Keff3zhwhlovCGbnj13qlaotm2qGFgZ/sbFnbhz9xZoPHzYWDDu4CnB8wELH7oq7OBdixZt4PKWrVgItwOqz184B2oC9Paw1Lge1L2x67+/ceMvGMCCm4G6buGCFWwGb9a0FTzfmM9mnDx1rJwUwLTevOkHiVgydvzgocOjrl3/8+MZMdDA6wO0bRMO5l77dhFvHsUoMXMXi0Xi4SP6DB7as2GDJqNHT4SfvaI6pD1NHTxoVNcuPVev+RJsiIuXzk4YPx2VmQwB3ZPx46bGxq6CMCDPqBET9GGg11q5UtDcmOk9e4V9uXxByxZtpk+bC+5g9EGvATLuxo2r4Sd0ej+e8Slkmsgebb9e9V9oGaOjtd1dR0dH6HaqVapu3dsMH9kHGqZKlaogMynnXY7xdv27BY8YDRU11fh3XAQAho+gmhk6ZDSybbbNj6/dwqV1lFdZLxNztGlKTV7hmgCq37v3bkHjDZ0u9A5g0m4zrr32k3Q7eocb2b2tKa9Zsz5v1bItMgew+JavWASmGYwCIZunnJmXJux8ZFffZsTG7jTl5ebqjsyE7bahdwRtm06Z07/Xzdezn3Lv64Pv3qfaYswYt+hNj+uRyZp2gW5xInPnapIp+nbBP5uvR7AHzB7X4/EpGuvd07DAxNoLKvIdrv1jos6nyPR8O4Gizfz+vuTSlYR3GO1rOYZ8k0UoCdEeX4xrL5TwGBXW+4PbDXwhok2sqWy8JydxQHI50d4eUCkY32ChUS/j2rfr61koI4b+O8/VUxkCIQqubXy2j3HtXTwkPlWE3y8pb7YTwfa5dT6rZQ8PU77lzce9dPT5X6dyfIOk/tUkEqkQvRZ2c4By/F/Xcyy7+4I5CZTny+5cYGbEchI07qXfCKHM2V9Okzd42KaeltGxFROXYsyZZnIy5En3CjJSFcM+CXR0Nynca+Zig/x3L8mKCtQqJXo9/35UgJNxBcuf9HWF4h8GNnrhNIVoAXJ05nf50NPd27Gc6DjujagnJiamefPmXbp0QViCdf9eP6keT4j2RHssIdrji1KpZBcAwBNS7km5xxKiPb4Q7fGFtPf4Qso9vhDt8YVojy9Ee3wh2uML0R5fiPb4QrTHFzK2gykMw2g0Gh6Ph3AFX+0xr/AR0R5hDNEeX/C9ecwNPUTKPcIYfG9erVaHhIQgjMF4ZIPPv3v3LsIYrLV/7RZa9g3RHl+I9vhCtMcXoj2+4LtyKkVRNE1DTw/hCtar5mJe9In2+GqP96Am0R5biPb4QrTHF6I9vhDt8YVojy9Ee3zBXHsc19WsX78+O6Cr0Wgo3RK+QN26dbdu3YpwAsdxverVq7MHID+bCRwdHYcNG4YwA0ftBw8eDGIbugQFBbVr1w5hBo7aR0ZGBgYG6n+KRKKBAwci/MD0Xc6oUaOkUil7HBAQEBERgfADU+2hhg8ODkY6U79///4ISzju4z26natWv+mXsIYbSlAvdw74x72UqIgJiqxdUqlDraAOD2/kv8lJ/wGmojNILRRSgSFOiDs46+N9tyAhL0vD4yE1dx1ss7azeOvQfO0FVAgU9pkciLiAG+03zI538xGEDfIVCt9gGx77JfVh3pl96c6e/H7TKiOrw4H262fFh7Rwati2AiLo2L/6IbQBw2KCkXWxtq13eGOyUMQjwhvSe1Jwfg7z+F4esi7W1j49qcjND+svn40icqCu/Z6FrIu17Xy1EkkdiPal4fH5cpm1zU5ra69Swn/ubGtbRaXQqAT2rj3BdiDa4wsH2lOkyi8DPBPa6o+FA+0x3oS1PBhE2ns8YZD1B9msrr12CJ0U/NJw8kSsrT2lHUwiDX5ptG+VrK6/9et8UuqNALYeY/e2nrZVI+LbBsTWswl4NMXjYWDnk/59WdQaRq22ezuf9O+NQVMUbfUygfWaK/+GXlHhqWkp6C2hYRiN/ffv7YKnT9Oys639uv2t8w6U+zt3bo4ZO6hLt/dnzZl8+/aNSVNGfbVyCeuVmZmxcNHc/gO79ezdYdGSmKSkx6z7Twf29O7T8cmTRyNG9W0X1mjUh/2PHjukTxASmTlrYvce7YYM673um6/y84sn6e7bvzvqg4hz5+PCwpusXrsMXC5ePLto8bx+A7p27tpqevS4v65dAUf4O2BQJBwMGtxj3qfRSLcc+4bYVXCurpGt4SIvXTqHzAQG8ykagzrfrHZNLpd/Mm+am5v7lk17Ro2csPabFc+fp1O6JNRq9bTosdeu/zlt6idbNv3g5uo+4aNhKanJ4CUQCGSyvFWrl34cHXPqt8ttWndY+uX89PSn4JWckjRj5gR5kXzN6m8XfLEsIeHBtOlj2K9xhUJhQUH+wYN758ye36tHXzj1oiXzioqKZs/6YvGilYGBlefOmwa5rX69RksWrYTw3+/4eeH85XAAJ9q7b2evnv12fn+oTeuwz76Y+fuZk8gctPW91et8Wy/3l/44l5OTPXbMFB8f3+rVQj4cPZGVELh58xqU7E/mLGjapIW7u8f4cVOdXVz37dvJ+iqVymFDx9SsWRsySkTHbjCuEB//N7j/9tsRAV8AqoOWlSsHzYiOeRD/N5R1pFttEfTu339Yh7BOAQGBYrF4U+zu6OlzQWz4P27s1MLCwpu3rpW6Qsgcx44fHjhgePfIKBdnly6de4S177Rt+0ZkFjDqoUFWxurtPWXekG5iYryjo2NQUFX2J2jg5OTMHoMMUL4b1G9cnDBF1avb8PqNq/q4ISGh7AEbBWoCpK3wr4O7i4sr6wVZys8v4MbNv9q26VAcq0aoPgWoBjZtXgNVS0bGC9albDN///5dhULRuFFzvQtcxpGjB2UyWakvPsuBoTgY6ebgXY5ZGTxPlieVOhi6uLq6sQegJRRuaM6N+iJdbiibIMS69/edUrGyMjP0x/pPBqCCmTJtdIP6TWLmLmbrj/CIZkYThL9ghZRyz83LeXPtOcHW7XyxSAylytAlI+M5e+Dh4SmRSBYt/MrQl0e/5gsvdw/P2rXrjRg+ztDRxdm1bMi430/AqaGxh7MgYyW++DI8veAvNA3+/hVLnMjNA70xYOfRNHl/XxJ4oPDQwcKCFh3pbOyCggLWKzi4OjTA3t4+/n4BrAt0uF1d3MpPMDio2vETv9St04Cmi22dR48SoHUvGzI3NwcaC1Z4wJT5FuAfKBKJkK49Yl2ysjLBvABzAb0x1L/97u+fYG1bTzs5iTbjJps1bcXj8Vav+RJ6YmCib9++ycvLm/Vq2KBJkyYtli1bAJUz2IMHfv5x3PghR48eLD/BPn0GaTSaNeuWg1kHfULom40c3S8hMb5syKCgatDMHzy0D3oBf/zvwtWr/wMr4dkzraVZMbAy/I2LO3Hn7i2pVDp82Fgw7sD2hHoCsgj0I1Z+/R9kDmrtBq3Iylj/PR7SaMyo3KBinzZ1zuYt66I+6FitWgiY7pAP+PziGf7Q1wJt5i+cA2MAFStW6tChc+/er/mg2tnJefOmH3bv/m7s+MHQTQC77+MZMdCDKBsyrH3E48cJICoMJzRu1GzWzM93/7Bt566teXm506d90iki8tut62uF1v1qxYb+/YZCJbRz91bIHw4OjqE160RHz0M2j7W/x1s342Glmk6to7zfPAp02aHuddbZ6nC13bq3GTl8fFTUAGRH/LAsUeLAGzTbqh/k2np7D5U5jNhUDa4+atRHMMKzefNamqLbtg1H9gUnth4H7T1lzjmhif3P4q+huH/62YyxYwdBfbt2zVZoCJDdgcOcLbN5771aK5avR3YNNLxqHObpkjlbZcFini4X7ywIxrH6HG1E5ucbAcaZKKu/VuOk3JMJe6WBgR0M3uORuZrGoCiKsv/3eKS9N4ZuKW9kZUh7bxNg8R6PtPdG0Whfc5B5ugRrQbTHF2trLxDRfAFp70vD4zPwH1kXa2sPwhfk47vtuCkYDSV1ftP1xN8W1h5M8qkizkgpRISSFMrUjSNckXWxtvadh/lp1Oj0vmREeMme5fFuFXi+law9qZebNdQ3xTwUSVHjCC//YGeEMbcvZt48m+UbJOo2KgBZHc72TtixNDH3ufadtcZY6w/DP0ZHAUy5l4Z5/acOpZKC52A4rFr6RIYJGhyX2MpDl0TZ6JTuV+nwjHbvBB4PBdSQdBvpj7iA470Rc54rFEoj7uyWhdpVaEpeHTRR7CuPEg+9bDB42HQJR31E9DI6SBK7cWPN0JotWrQoG4BmKI3B+KOhb8nEX10IxWhVZn/QFKX/phrcGUp/rE1Yd6h2dEP6CeCcwHH/3sWLy30z8oqSxU7BXn6Y7t2B9diOUqkUCPBd0J1oT7THEpVKxefj+wRw156Ue0yBOp+Ue0whdT6+EO3xhWiPL0R7fCHa4wvRHl/IuB6+kHKPL0R7fCHa4wvRHlMY7ZJ2Gh7P2jOjbQd8tce80COiPcIYoj2+EO3xhWiPL1hrHxoaijAGX+2hd3fnzh2EMRiPbPD57PZY2EK0xxeiPb4Q7fGFaI8v+O6Dze6TpbH+FkU2A9Z7oGNe9In2+GqP96Am0R5biPb4QrTHF6I9vhDt8YVojy8CgUCpVCJcIeUe33LP8bqanBAeHs7j8dRqdU5ODhR9OFAoFIGBgQcOHEA4gWO5d3R0TEpKYo+Liorgr1gsHj58OMIMHMd0e/Xqxb7I0RMQENCzZ0+EGThqP2DAAH//V0tXQ6sfFRWF8ANH7aGNB/lFIhH7E/JBZGQkwg9M3+P17du3YsWKSLdYe7du3aRSKcIPfN/hDho0SCKRQA7AsKVnsfU+3l9xmfevyvKylAo5w6jZbTWNBDPcs+IVENToDsPGdtUw3IzBVPRSm2mUOikc0TxE0ZRIQrlVEDQMcwusYe0tcMzCdrX/ceWTZ0kKOOCJeWIHodRVJHESUCIhr/T16lTT7Vmhd2J0+26UcnzlazRLmAisP4ORiCWjaNRIqVLKcxSFOXKFTKFSaHgCFFTHoeMgX2ST2KL2hzenPrpVwBfRXlVcPQJd0DtLyp1nOen5kB466MYAAAXrSURBVD2ad/Oo18YN2Rg2p33sJwlQgALqeTu6crmXzFskPT7zxeMcN2/BwJmVkC1hW9qvm/HQyVtSsXYFZHfEX0jSqDVjFgchm8GGtF8zPT6grqertxOyU+IvJgkEzLCYKsg2sJU+3tro+MD69iw8ULV5RRVDr58dj2wDm9B+w+yHLhUcnD3tWXiW4MYB0AvcvfwxsgG4137f6mToOgXU9kZ4ENK60otk5b2ruYhruNc+LUFerRUHu8FyiLOfw5kfnyOu4Vj7XUsfCx34uC1wGFjLW6lk/jjyAnEKx9pnPlX61PBAtsqXqwfsO7QUWQCpq/jmuRzEKVxqf+andIpHOXvi+A4tsJ63vIDj3jWX2j+6UyiUYDpZVNvM0ejUnqeIO7h89LIslYufpd50qdWqI7+tv3v/fHb20yqV6rZo+kHNGi1Zr8+WRESEjckvyD5+apNIKKlRrVmPztOdnT3B6+mzhN375qc/T6wa1LBDm5HIkvCFdGqCHHEHl+Uexu2dvCxV4f90eNnZi7taNf3gk+gDtUPbb9s9+8atU6wXjyeIO7eDouj5c47PnLwn8fH1Y6c3Iu2Ke8pN26a6unjPnPxD144TIUxengXNMbGDSC7jcuUHzrRnF7xw9nRAFkCpLLpy7Zf27w9r3qS3g9SlacPu9etEnIjbrA/g6R7Qoc0IicQJinuNqs2SU+6B4807p7Nz0rt3nubm6uPjHdSr24xCeR6yGAIJTyHHUvu8bAt+FJGUelelUlSv2lTvEly5QVp6fH5BsWkd4P+e3ksicZYXyeDgRUaSUCB2dyt+3e7s5OnqYsG3Sjw+zXC64Atn7b1QQFvuLZK8UKvl2k1jSrnnyTKgGtAdGpnPU1CYKxSVaIMEfDGyGBoG8QQU4g7OtJc48SkKFcgKpY5v/z09a7j16THH072iobubi085saQS56KiAkMXeVE+shgquYrmY6k9QPOR7JlFtPfyCBQItFOwwVxnXfJkmfC2WiQqz7R0c/VVKuXQNPhWqAo/U9Lu5+ZZcOS1qFApkXJpa3N5brGUl59pkU4OaNyx3YcnTm9OeHxNqVKAhR+7ddL+w68ZoQt9rzWfL/zxwBKFQp6T+3zHnnlSqQVnjKnlKncfIeIOLsu9d6Aw+X4Rsgzt3h/i51v99NltDx5eFosdK1es/UGPT8qPIhE7jhq84pfja+Ytag9GH3Tzrt44ZrlKWa1k6rd3RtzB5bwdhUIRO+tJrY62Mo/FmqTee5H7VDbuv8GIO7is84VCoYMzL/FKGsIPEN6/mghxCsfD6c27e5za9aycALHfTX6SfNuoF4za8njGr79/709rvdcGvSVOnfnu1NltJjyNfNPBMn3Cdnc3P6NeWWm5ajUTOZrjWQvcz9Xc+kWihuIHNTb+mHLzXsAojVEvhbJIKDBedBwd3IXCt9Y1LyzMMzXAl1+Q6yA13ma7OHubypp34x5VCZV0Gmr8lq2GTczTXTs9vkoTH6mLnUzIL5/H158qZUWjF3I/Wdsm5mq+39Mj8TKXbzOtRt6LAtmLQlsQHtmI9nVau9Vu6XTreCKya5RFysdX08cvtZXPM2zo24xHd/J/2ZIW8n4gT2iH0/eexme+SMwZ/2UV25mcaFvfZF06mnHlWJajh7hyQxv9dvWfEX8+SaVQj1vKZW++LLb4HW7s3IeKQsbFR2oHH+Y9vJJamF3kXkE4cGYgsjFs9Pv784efX4/L0ai1ExycPKUelZ1FEi6Hvs1CllmQkZxbmKVQKdUweNVhoGfFarb4yZFNr7tx72rOn8ezczOUahWiaO04inZNBbXRsC+XRWDvhjI4QCVHX6iXy2cYhqR0S3EYuFDsr7KpMdorKZ5zQb1cwuPVuRjdPyQUU17+wvYDPF3cbbfj+s6sqxl/PSczXVVUqGZUr16v6DXSYWyIrdQyKcX6IKpUSOOjc5RuoQ3m1dnYrFQ6cPFvGMiRONHegeKAqhaZiPbWwXFNVQIL1mspYw7RHl+I9vhCtMcXoj2+EO3x5f8AAAD//4tzT18AAAAGSURBVAMAL19FxDjUAGIAAAAASUVORK5CYII=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(adjusted_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify the improved pipeline works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The provided context does not specify the specific methods or strategies Stone Ridge uses to approach risk management in their energy investments. It mentions that Stone Ridge Energy (SRE) has purchased a substantial amount of energy assets through proprietary securitizations, emphasizing a structure that avoids bankers, information leakage, and fee leakage. The context also highlights their experience with volatile natural gas prices but does not detail particular risk management techniques.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = adjusted_graph.invoke({\"question\": \"How does Stone Ridge approach risk management in their energy investments?\"})\n",
    "response[\"response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Improved Evaluation\n",
    "\n",
    "Now let's run the same synthetic test set through our improved pipeline and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "rerank_testset = copy.deepcopy(testset)\n",
    "\n",
    "for test_row in rerank_testset:\n",
    "    response = adjusted_graph.invoke({\"question\": test_row.eval_sample.user_input})\n",
    "    test_row.eval_sample.response = response[\"response\"]\n",
    "    test_row.eval_sample.retrieved_contexts = [context.page_content for context in response[\"context\"]]\n",
    "    time.sleep(2)  # To avoid rate limiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa8ebcec8c68408399a6b486dbde282c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'context_recall': 0.4833, 'faithfulness': 0.7290, 'factual_correctness': 0.4680, 'answer_relevancy': 0.8495, 'context_entity_recall': 0.3697, 'noise_sensitivity_relevant': 0.2852}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rerank_evaluation_dataset = EvaluationDataset.from_pandas(rerank_testset.to_pandas())\n",
    "\n",
    "rerank_result = evaluate(\n",
    "    dataset=rerank_evaluation_dataset,\n",
    "    metrics=[\n",
    "        LLMContextRecall(),\n",
    "        Faithfulness(),\n",
    "        FactualCorrectness(),\n",
    "        ResponseRelevancy(),\n",
    "        ContextEntityRecall(),\n",
    "        NoiseSensitivity(),\n",
    "    ],\n",
    "    llm=evaluator_llm,\n",
    "    run_config=custom_run_config,\n",
    ")\n",
    "rerank_result\n",
    "\n",
    "# previous metrics\n",
    "# {'context_recall': 0.0833, 'faithfulness': 0.4631, 'factual_correctness': 0.3767, 'answer_relevancy': 0.5616, 'context_entity_recall': 0.2324, 'noise_sensitivity_relevant': 0.0234}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Question #4:\n",
    "\n",
    "Which system performed better, on what metrics, and why?\n",
    "\n",
    "##### ‚úÖ Answer:\n",
    "\n",
    "The seconc, adjusted, system worked better, as graded by every metric except 'noise_sensitivity_relevant': context_recall, faithfulness, factual_corectness, answer_relevancy, context_entity_recall\n",
    "The system with a larger, more dense, corpus of document data beceoms more sensitive to noisy or irrelevant documents. \n",
    "<br><br>\n",
    "The second system used larger chunks of text for embeddring model inputs, allowing more complex and denser facts to be extracted. It used more documents in total for its search speace, and then also selected the top 5 most relevant documents from that space for similarity comparison. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Question #5:\n",
    "\n",
    "What are the benefits and limitations of using synthetic data generation for RAG evaluation? Consider both the practical advantages and potential pitfalls.\n",
    "\n",
    "##### ‚úÖ Answer:\n",
    "\n",
    "Benefits: faster to generate, less tedious manual input, can cover a broad set of potential use cases\n",
    "<br><br>\n",
    "Limitations: synthetic questions are only as \"creative\" as the underlying model allows them to be, they may miss first-order and second-order connections that humans may instictively know and assume the RAG system to know as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Question #6:\n",
    "\n",
    "If you were building a production investment advisory assistant for Stone Ridge, which Ragas metrics would be most important to optimize for and why? Consider the financial services domain specifically.\n",
    "\n",
    "##### ‚úÖ Answer:\n",
    "For a production investment assistant every metric listed above would be relevant. You want your answers to be always be correct and as faithful as possible when large amounts of money and client trust are at stake. You would also want low sensitivity to document noise, as much of the data in the financial world is noisy, dirty and full of irrelevant dimensions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üèóÔ∏è Activity #2: Implement a Different Reranking Strategy\n",
    "\n",
    "Experiment with different reranking parameters or strategies to see how they affect the evaluation metrics.\n",
    "\n",
    "**Requirements:**\n",
    "1. Modify the `retrieve_adjusted` function to use different parameters (e.g., change `k` values, try different `top_n` for reranking)\n",
    "2. Or implement a different retrieval enhancement strategy (e.g., hybrid search, query expansion)\n",
    "3. Run the evaluation and compare results with the baseline and reranking results above\n",
    "4. Document your findings in the markdown cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a443b2404d164d618ac48d3b9285265a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[8]: AttributeError('StringIO' object has no attribute 'statements')\n",
      "Exception in callback Task.__step()\n",
      "handle: <Handle Task.__step()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "    ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: cannot enter context: <_contextvars.Context object at 0x10c0da380> is already entered\n",
      "Exception raised in Job[11]: AttributeError('StringIO' object has no attribute 'statements')\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-4529' coro=<_async_in_context.<locals>.run_in_context() done, defined at /Users/alexei.naumann/Desktop/AIE/AI-Engineering/07_Synthetic_Data_and_Evaluation/.venv/lib/python3.13/site-packages/ipykernel/utils.py:57> wait_for=<Task pending name='Task-4530' coro=<Kernel.shell_main() running at /Users/alexei.naumann/Desktop/AIE/AI-Engineering/07_Synthetic_Data_and_Evaluation/.venv/lib/python3.13/site-packages/ipykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at /Users/alexei.naumann/Desktop/AIE/AI-Engineering/07_Synthetic_Data_and_Evaluation/.venv/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py:563]>\n",
      "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/weakref.py:415: RuntimeWarning: coroutine 'Kernel.shell_main' was never awaited\n",
      "  return self.data[ref(key)]\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-4530' coro=<Kernel.shell_main() running at /Users/alexei.naumann/Desktop/AIE/AI-Engineering/07_Synthetic_Data_and_Evaluation/.venv/lib/python3.13/site-packages/ipykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\n",
      "Exception raised in Job[53]: AttributeError('StringIO' object has no attribute 'statements')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context_recall': 0.5083, 'faithfulness': 0.7086, 'factual_correctness': 0.5178, 'answer_relevancy': 0.8502, 'context_entity_recall': 0.3747, 'noise_sensitivity_relevant': 0.2461}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Implement your custom retrieval strategy here\n",
    "# Example: modify retrieve_adjusted with different parameters\n",
    "\n",
    "def retrieve_custom(state):\n",
    "    compressor = CohereRerank(model=\"rerank-v3.5\")\n",
    "    compression_retriever = ContextualCompressionRetriever(\n",
    "        base_compressor=compressor,\n",
    "        base_retriever=adjusted_retriever,\n",
    "        search_kwargs={\"k\": 10},\n",
    "    )\n",
    "    retrieved_docs = compression_retriever.invoke(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "class CustomGraphState(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    response: str\n",
    "\n",
    "custom_graph_builder = StateGraph(CustomGraphState).add_sequence([retrieve_custom, generate])\n",
    "custom_graph_builder.add_edge(START, \"retrieve_custom\")\n",
    "custom_graph = custom_graph_builder.compile()\n",
    "\n",
    "rerank_testset = copy.deepcopy(testset)\n",
    "\n",
    "for test_row in rerank_testset:\n",
    "    response = custom_graph.invoke({\"question\": test_row.eval_sample.user_input})\n",
    "    test_row.eval_sample.response = response[\"response\"]\n",
    "    test_row.eval_sample.retrieved_contexts = [context.page_content for context in response[\"context\"]]\n",
    "    time.sleep(2)  # To avoid rate limiting\n",
    "\n",
    "rerank_evaluation_dataset = EvaluationDataset.from_pandas(rerank_testset.to_pandas())\n",
    "\n",
    "rerank_result = evaluate(\n",
    "    dataset=rerank_evaluation_dataset,\n",
    "    metrics=[\n",
    "        LLMContextRecall(),\n",
    "        Faithfulness(),\n",
    "        FactualCorrectness(),\n",
    "        ResponseRelevancy(),\n",
    "        ContextEntityRecall(),\n",
    "        NoiseSensitivity(),\n",
    "    ],\n",
    "    llm=evaluator_llm,\n",
    "    run_config=custom_run_config,\n",
    ")\n",
    "rerank_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# previous metrics\n",
    "# {'context_recall': 0.0833, 'faithfulness': 0.4631, 'factual_correctness': 0.3767, 'answer_relevancy': 0.5616, 'context_entity_recall': 0.2324, 'noise_sensitivity_relevant': 0.0234}\n",
    "\n",
    "# Adjusted Results\n",
    "# {'context_recall': 0.4833, 'faithfulness': 0.7290, 'factual_correctness': 0.4680, 'answer_relevancy': 0.8495, 'context_entity_recall': 0.3697, 'noise_sensitivity_relevant': 0.2852}\n",
    "\n",
    "# Custom metrics\n",
    "# {'context_recall': 0.5083, 'faithfulness': 0.7086, 'factual_correctness': 0.5178, 'answer_relevancy': 0.8502, 'context_entity_recall': 0.3747, 'noise_sensitivity_relevant': 0.2461}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity #2 Findings:\n",
    "\n",
    "| Metric | Previous | Adjusted | Custom |\n",
    "|---|---|---|---|\n",
    "| context_recall | 0.0833 | 0.4833 | 0.5083 |\n",
    "| faithfulness | 0.4631 | 0.7290 | 0.7086 |\n",
    "| factual_correctness | 0.3767 | 0.4680 | 0.5178 |\n",
    "| answer_relevancy | 0.5616 | 0.8495 | 0.8502 |\n",
    "| context_entity_recall | 0.2324 | 0.3697 | 0.3747 |\n",
    "| noise_sensitivity_relevant | 0.0234 | 0.2852 | 0.2461 |\n",
    "\n",
    "For the custom retriever, I simnply increaed the number of documents that were passed to Cohere for reranking. Increasing this value from 5 to 10 improved the system's context recall, factual_corectness, answer relevancy, context entity recall. Changing that value also decreased the faithfulness metric and gave a higher noise sensitivity vale than the base models. This means it was more likely to halucinate data and be sensitive to document noise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "In this notebook, we went end-to-end from data generation to evaluation:\n",
    "\n",
    "1. **Built a knowledge graph** from our investment documents (Stone Ridge 2025 Investor Letter and Alternative Investments Handbook) and used it to understand the structure of our data\n",
    "2. **Generated synthetic test data** with diverse query types (single-hop, multi-hop abstract, multi-hop specific)\n",
    "3. **Built a baseline RAG pipeline** with deliberately simple parameters\n",
    "4. **Evaluated with Ragas** across six metrics to establish a baseline\n",
    "5. **Improved the pipeline** with larger chunks and Cohere reranking\n",
    "6. **Re-evaluated** to measure the impact of our changes\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "- **Synthetic data generation** is critical for early iteration ‚Äî it provides high-quality signal without manually creating test data\n",
    "- **Ragas metrics** give you a multi-dimensional view of RAG quality (retrieval vs. generation vs. faithfulness)\n",
    "- **Small changes matter** ‚Äî chunk size, retrieval strategy, and reranking can dramatically affect evaluation scores\n",
    "- **Always use a different model for judging** than for generating to avoid self-evaluation bias"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "07-synthetic-data-and-evaluation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
